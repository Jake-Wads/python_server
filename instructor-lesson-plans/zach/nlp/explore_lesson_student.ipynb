{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP EDA\n",
    "\n",
    "Basically, exploration and modeling boil down to a single question:\n",
    "\n",
    "How do we quantify our data (/a document)?\n",
    "\n",
    "In this lesson, we'll explore answers to this question that will aid in visualization.\n",
    "\n",
    "- word frequency (by label)\n",
    "- ngrams\n",
    "- word cloud\n",
    "- sentiment analysis\n",
    "- other common features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Data is spam/ham text messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(13, 7))\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data comes from https://www.kaggle.com/uciml/sms-spam-collection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./spam_clean.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_words = clean(' '.join(df[df.label == 'ham'].text))\n",
    "spam_words = clean(' '.join(df[df.label == 'spam'].text))\n",
    "all_words = clean(' '.join(df.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "Represent text as word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_freq = pd.Series(ham_words).value_counts()\n",
    "spam_freq = pd.Series(spam_words).value_counts()\n",
    "all_freq = pd.Series(all_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.concat([ham_freq, spam_freq, all_freq], axis=1).fillna(0).astype(int)\n",
    "word_counts.columns = ['ham', 'spam', 'all']\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What are the most frequently occuring words?\n",
    "- Are there any words that uniquely identify a spam or ham message? I.e. words present in one type of message but not the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "- ham vs spam count for 20 most common words\n",
    "- ham vs spam proportion for 20 most common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams\n",
    "\n",
    "**bigram**: combinations of 2 words\n",
    "\n",
    "Technique 2: represent text as combinations of 2 words\n",
    "\n",
    "- what are the most common bigrams? spam bigrams? ham bigrams?\n",
    "- visualize 20 most common bigrams, most common ham bigrams\n",
    "- ngrams\n",
    "\n",
    "Find the most common bigram and then find a representative text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "img = WordCloud(background_color='white', width=800, height=600).generate(' '.join(all_words))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Common Features\n",
    "\n",
    "Any NLP dataset will have domain specific features, for example: number of retweets, number of @mentions, number of upvotes, or mean time to respond to a support chat. In addition to these domain specific features, some common measures for a document are:\n",
    "\n",
    "- character count\n",
    "- word count\n",
    "- sentence count\n",
    "- stopword count\n",
    "- unique word count\n",
    "- punctuation count\n",
    "- average word length\n",
    "- average words per sentence\n",
    "- word to stopword ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one or more of the above features and visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment\n",
    "\n",
    "A number indicating whether the document is positive or negative.\n",
    "\n",
    "- knowledge-based + statistical approach\n",
    "- relies on human-labelled data\n",
    "    - valence scored wordlists\n",
    "    - overall labels, measure is how well it compares to human judgement\n",
    "- different models for diff domains (e.g. social media vs news)\n",
    "- for social media\n",
    "    - Afinn ([github](https://github.com/fnielsen/afinn) + [whitepaper](http://www2.imm.dtu.dk/pubdb/edoc/imm6006.pdf))\n",
    "    - Vader ([whitepaper](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf) `nltk.sentiment.vader.SentimentIntensityAnalyzer`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.sentiment\n",
    "\n",
    "sia = nltk.sentiment.SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores('This food is bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this to the text message data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Resources\n",
    "\n",
    "- [kaggle wikipedia movie plots](https://www.kaggle.com/jrobischon/wikipedia-movie-plots)\n",
    "    - Suggestion: narrow to top n genres that aren't unknown\n",
    "- [wikitable extractor](https://wikitable2csv.ggor.de/) (Try with, e.g. [helicopter prison escapes](https://en.wikipedia.org/wiki/List_of_helicopter_prison_escapes))\n",
    "- [Textblob library](https://textblob.readthedocs.io/en/dev/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

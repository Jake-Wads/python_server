{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c43548f-65e6-4126-aeef-37f21f607cd8",
   "metadata": {},
   "source": [
    "# Spark API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enclosed-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prostate-making",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.52:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fadd928e790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f4b3b-2d9d-422f-b98f-ce16519070e3",
   "metadata": {},
   "source": [
    "For demonstration, we'll create a spark dataframe from a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "located-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unsigned-boring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = pydataset.data('tips')\n",
    "df = spark.createDataFrame(tips)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-railway",
   "metadata": {},
   "source": [
    "## DataFrame Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593103d-aa7b-49b2-a1b9-606e14bbe864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079778d7-a1ca-4246-8127-1787de0c8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't do this!\n",
    "# just use .show to view df contents\n",
    "df2 = df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecdb17-0908-4917-bbdf-af2c7718a9fe",
   "metadata": {},
   "source": [
    "### Selecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('total_bill', 'tip', 'size', 'day').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df.tip / df.total_bill).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df.tip / df.total_bill\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('*', col.alias('tip_pct')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_tip_pct = df.select('*', col.alias('tip_pct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_tip_pct.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1b18e-8155-46c1-b82e-09ee06a31caf",
   "metadata": {},
   "source": [
    "### Selecting w/ Built In Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, mean, concat, lit, regexp_extract, regexp_replace, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(mean(df.tip), sum(df.total_bill)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(concat('day', lit(' '), 'time')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(df.time.cast('int')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\n",
    "    '*',\n",
    "    (df.tip / df.total_bill).alias('tip_pct')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe548f-0d9f-48f5-92cf-df2631ec8e8b",
   "metadata": {},
   "source": [
    "### When / Otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    'tip_pct',\n",
    "    (when(df.tip_pct > .2, 'good tip')\n",
    "     .otherwise('not good tip')\n",
    "     .alias('tip_desc'))\n",
    ").show(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab6553-9ffa-4f91-9058-42a9cdb3e388",
   "metadata": {},
   "source": [
    "### Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b0628f-bbd4-4d52-98a4-1fc4db9b5e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    'time',\n",
    "    regexp_extract('time', r'(\\w).*', 1).alias('first_letter'),\n",
    "    regexp_replace('time', r'[aeiou]', 'X')\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-reward",
   "metadata": {},
   "source": [
    "## Transforming Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d4fdf-7fce-4756-8d36-36de8b159a40",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.orderBy(df.total_bill).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(df.day, df.size).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, desc, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(df.day, asc('time'), desc('size')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "col('size').asc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort(col('size').desc(), col('time')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce707546-351b-44f7-a73f-8d68d6e61800",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df.tip < 4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.tip < 4\n",
    "df.where(mask).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter((df.time == \"Dinner\") | (df.tip <= 2)).sort('tip').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df.smoker == \"Yes\").where(df.day == \"Sat\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-radius",
   "metadata": {},
   "source": [
    "## Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('time').agg(mean('tip')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('time').agg(min('tip'), mean('tip'), max('tip')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('time').agg(mean('tip').alias('avg_tip')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('time', 'day').agg(mean('total_bill')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.crosstab('time', 'day').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('time').pivot('day').agg(mean('total_bill')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-superintendent",
   "metadata": {},
   "source": [
    "`.crosstab` is just for counts, for other methods of summarizing groups, use `.groupBy` (maybe in combination with `.pivot`) + `.agg`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-enterprise",
   "metadata": {},
   "source": [
    "## Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd3a797-38d5-4479-8882-8f2d1e1d0f28",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "SELECT *\n",
    "FROM tips\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the tip, total_bill, and day with the highest overall sales for that day\n",
    "spark.sql('''\n",
    "SELECT tip, total_bill, day\n",
    "FROM tips\n",
    "WHERE day = (\n",
    "    SELECT day\n",
    "    FROM tips\n",
    "    GROUP BY day\n",
    "    ORDER BY sum(total_bill) DESC\n",
    "    LIMIT 1\n",
    ")    \n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5f56d-6207-43bb-9c03-a78cb4169e26",
   "metadata": {},
   "source": [
    "### More Spark Dataframe Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(\n",
    "    df.time == 'Dinner'\n",
    ").select(\n",
    "    '*',\n",
    "    (df.tip / df.total_bill).alias('tip_pct'),\n",
    ").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    '*',\n",
    "    (df.tip / df.total_bill).alias('tip_pct'),\n",
    ").where(\n",
    "    df.time == 'Dinner'\n",
    ").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef8adf1-d36d-4f1b-92fb-44a9b77b4940",
   "metadata": {},
   "source": [
    "### Mixing in SQL Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-zambia",
   "metadata": {},
   "source": [
    "Expr lets us mix in parts of SQL into our dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    '*',\n",
    "    expr('tip / total_bill as tip_pct')\n",
    ").where(\n",
    "    expr('day = \"Sun\" AND time = \"Dinner\"')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99023336-20d4-4aa7-9203-980ef6923dae",
   "metadata": {},
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7271b43d-b233-4953-af7e-7d5f0613f422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+\n",
      "| id|     x|group_id|\n",
      "+---+------+--------+\n",
      "|  1| 0.069|       4|\n",
      "|  2| 1.043|       2|\n",
      "|  3|-1.496|       1|\n",
      "|  4| 0.282|       1|\n",
      "|  5|  0.77|       5|\n",
      "+---+------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+-----+\n",
      "| id|group|\n",
      "+---+-----+\n",
      "|  1|    a|\n",
      "|  2|    b|\n",
      "|  3|    c|\n",
      "|  4|    d|\n",
      "|  5|    e|\n",
      "|  6|    f|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.createDataFrame(pd.DataFrame({\n",
    "    'id': np.arange(100) + 1,\n",
    "    'x': np.random.randn(100).round(3),\n",
    "    'group_id': np.random.choice(range(1, 7), 100),\n",
    "}))\n",
    "df2 = spark.createDataFrame(pd.DataFrame({\n",
    "    'id': range(1, 7),\n",
    "    'group': list('abcdef')\n",
    "}))\n",
    "df1.show(5)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1cea3b5-b4b9-40bf-918f-714e9f43892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------+---+-----+\n",
      "| id|     x|group_id| id|group|\n",
      "+---+------+--------+---+-----+\n",
      "|  6| 0.031|       6|  6|    f|\n",
      "|  8| 0.019|       6|  6|    f|\n",
      "| 13| 0.972|       6|  6|    f|\n",
      "| 19|-0.787|       6|  6|    f|\n",
      "| 25| -0.17|       6|  6|    f|\n",
      "+---+------+--------+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_merged = df1.join(df2, df1.group_id == df2.id)\n",
    "df_merged.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "345af9c6-3a75-451c-a435-4c17bfb47083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+-----+\n",
      "|group_id| id|     x|group|\n",
      "+--------+---+------+-----+\n",
      "|       6|  6| 0.031|    f|\n",
      "|       6|  8| 0.019|    f|\n",
      "|       6| 13| 0.972|    f|\n",
      "|       6| 19|-0.787|    f|\n",
      "|       6| 25| -0.17|    f|\n",
      "+--------+---+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2.withColumnRenamed('id', 'group_id'), 'group_id').show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

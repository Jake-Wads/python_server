
1. Attributes: Attributes are one particular "type of data" in your points,so each observation/datapoint (like personal record) contains many different attributes (like person weight, height, age, etc.). The attribute are the independent variables before the features are selected, i.e. before you know which are going to be used to build a model.  You may see these referred to as (independent) variables, columns, or fields.  
1. Features: Briefly, the features are the variables that are being manipulated in an experiment in order to observe the effect on a dependent variable, which is sometimes referred to as a target or outcome variable. The features are the independent variables that are used to build a model. They may come directly or indirectly from the attributes. You may see these referred to as predictors, experimental variables or independent variables. The extended version is this: 
    - It sometimes refers to attribute
    - It sometimes refers to the internal representation of the data generated by particular learning model, for example - neural networks extract features which are combinations of the attributes or other features
    - It sometimes refers to the hypothethical representation of the data induced by the kernel method (in Kernel PCA, Kernel k-means, SVM)
    - In general you have some objects X, which you describe using some attributes (which is the first step of feature extraction, and so these attributes are also sometimes refered as features), which creates a representation of given dimension (number of attributes, extracted features). Then you train some model, which often creates some kind of abstraction (sometimes even multi-level), and each of such abstractions generate new features (extracts features from features) which are more complex objects then the ones on the lower "level".
1. Target: The target variable is the dependent variable, or outcome variable, and is what is being predicted in a model or observed in an experiment. 
Dimension usually refers to the number of attributes, although it can also be used in form of "second dimension of the data vector is person age", but it is rather rare - in most cases dimension is "number of attributes"
1. Scaling: normalization, scaling numeric data to new units, e.g. min-max scaling, center & scale, log-scaling
1. Standardization: Scaling to a standard unit by dividing by the standard deviation. The z-score is a way to standardize data $\frac{(x-\mu)}{\sigma}$
1. Text normalization: The process of transforming text into a single canonical form that it might not have had before. Normalizing text before storing or processing it allows for separation of concerns, since input is guaranteed to be consistent before operations are performed on it.
1. Graph: a diagram of a mathematical function, but can also be used (loosely) about a diagram of statistical data.
1. Chart: a graphic representation of data, where a line chart is one form.
1. Plot: the result of plotting statistics as a diagram in different ways, where some of the ways are similar to some chart types.
    - From these definitions, a line chart could be called a graph or a plot, while a pie chart is neither a graph nor a plot. A scatterplot is a chart but not (strictly) a graph, but the purpose of a scatterplot is to determine if there is some relation that can be expressed as a function that then naturally can be drawn as a graph.
1. Hyperparameters
1. Parameters

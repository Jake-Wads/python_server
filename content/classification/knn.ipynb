{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor\n",
    "\n",
    "\n",
    "**What is KNN?**\n",
    "\n",
    "- Supervised Algorithm\n",
    "\n",
    "- Makes predictions based on how close a new data point is to known data points.\n",
    "\n",
    "- Considered a **lazy algorithm** in that it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the k nearest neighbors of each point.\n",
    "\n",
    "- Predictions are made for a new data point by searching through the entire training set for the K most similar instances (the neighbors) and summarizing the output variable for those K instances.  For regression problems, this might be the mean output variable. For classification problems, this might be the mode (or most common) class value.\n",
    "\n",
    "- It is important to define a metric to measure how similar data instances are. Euclidean distance can be used if attributes are all on the same scale (or you convert them to the same scale).\n",
    "\n",
    "![KNN](knn2.jpg)\n",
    "\n",
    "Reference: <a href= \"https://cambridgecoding.wordpress.com/2016/01/16/machine-learning-under-the-hood-writing-your-own-k-nearest-neighbour-algorithm/\">Cambridge Coding Academy</a>\n",
    "\n",
    "\n",
    "**Pros**\n",
    "\n",
    "1. Simple to implement\n",
    "\n",
    "2. Performs calculations \"just in time\", i.e. when a prediction is needed (as opposed to ahead of time)\n",
    "\n",
    "3. Training instances can be updated and curated over time to keep predictions accurate.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "1. Need to determine the value of K\n",
    "\n",
    "2. The computation cost is high as it needs to compute the distance of each instance to all the training samples...you need to hang on to your entire training dataset. Therefore, not ideal for use on big data.\n",
    "\n",
    "3. Distance can break down in very high dimensions, negatively affecting the performance. This is know as the \"Curse of dimensionality\". To alleviate, only use those input variables that are most relevant to predicting the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "1           5.1          3.5           1.4          0.2  setosa\n",
       "2           4.9          3.0           1.4          0.2  setosa\n",
       "3           4.7          3.2           1.3          0.2  setosa\n",
       "4           4.6          3.1           1.5          0.2  setosa\n",
       "5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "# read Iris data from pydatset\n",
    "df = data('iris')\n",
    "\n",
    "# convert column names to lowercase, replace '.' in column names with '_'\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Validate Test\n",
    "\n",
    "Now we'll do our train/validate/test split:\n",
    "\n",
    "- We'll do exploration and train our model on the `train` data\n",
    "\n",
    "- We tune our model on `validate`, since it will be out-of-sample until we use it.\n",
    "\n",
    "- And keep the `test` nice and safe and separate, for our final out-of-sample dataset, to see how well our tuned model performs on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='species', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['species'])\n",
    "y_train = train.species\n",
    "\n",
    "X_validate = validate.drop(columns=['species'])\n",
    "y_validate = validate.species\n",
    "\n",
    "X_test = test.drop(columns=['species'])\n",
    "y_test = test.species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "**Create KNN Object**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = ['uniform', 'distance']\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model** \n",
    "\n",
    "Fit the model to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions**\n",
    "\n",
    "Classify each flower by its estimated species. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimate Probability**\n",
    "\n",
    "Estimate the probability of each species, using the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "**Compute the Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.99\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  0  0]\n",
      " [ 0 27  1]\n",
      " [ 0  0 28]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a classification report**\n",
    "\n",
    "\n",
    "**Precision:** $\\frac{TP}{(TP + FP)}$\n",
    "\n",
    "**Recall:** $\\frac{TP}{(TP + FN)}$\n",
    "\n",
    "**F1-Score:** A measure of accuracy. The harmonic mean of precision & recall. The harmonic mean is the reciprocal of the arithmetic mean of the reciprocals.  \n",
    "\n",
    "F1 $\\in [0, 1]$\n",
    "\n",
    "F1-score = harmonic mean = $\\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}}$\n",
    "\n",
    "**Support:** number of occurrences of each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      0.96      0.98        28\n",
      "   virginica       0.97      1.00      0.98        28\n",
      "\n",
      "    accuracy                           0.99        84\n",
      "   macro avg       0.99      0.99      0.99        84\n",
      "weighted avg       0.99      0.99      0.99        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________\n",
    "\n",
    "Let's look at how this works manually and through simple visual classification. \n",
    "We start with 4 *labeled* samples here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c    d      target\n",
       "0  5.7  2.6  3.5  1.0  versicolor\n",
       "1  5.5  3.5  1.3  0.2      setosa\n",
       "2  6.3  2.8  5.1  1.5   virginica"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first_nearest_neighbor\n",
    "import pandas as pd\n",
    "samples = pd.DataFrame({'a': [5.7, 5.5, 6.3], \n",
    "                        'b': [2.6, 3.5, 2.8], \n",
    "                        'c': [3.5, 1.3, 5.1], \n",
    "                        'd': [1.0, 0.2, 1.5], \n",
    "                        'target': ['versicolor', 'setosa', 'virginica']\n",
    "                       })\n",
    "\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add 3 new unlabeled observations. \n",
    "For each observation, we look to the labeled samples to see which one it is closer to, in order to find the \"1st-Nearest Neighbor\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.30</td>\n",
       "      <td>2.80</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.25</td>\n",
       "      <td>2.77</td>\n",
       "      <td>5.09</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a     b     c     d\n",
       "0  6.30  2.80  5.10  1.40\n",
       "1  6.25  2.77  5.09  1.35\n",
       "2  5.50  3.50  1.29  0.30"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs = pd.DataFrame([[6.3, 2.8, 5.1, 1.4], \n",
    "                       [6.25, 2.77, 5.09, 1.35], \n",
    "                       [5.5, 3.5, 1.29, 0.3]], \n",
    "                        columns = ['a', 'b', 'c', 'd'])\n",
    "\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is pretty clear which samples each new observation corresponds to. So we add those predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>pred_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.30</td>\n",
       "      <td>2.80</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.40</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.25</td>\n",
       "      <td>2.77</td>\n",
       "      <td>5.09</td>\n",
       "      <td>1.35</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a     b     c     d pred_target\n",
       "0  6.30  2.80  5.10  1.40   virginica\n",
       "1  6.25  2.77  5.09  1.35   virginica\n",
       "2  5.50  3.50  1.29  0.30      setosa"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_target = pd.DataFrame(['virginica', 'virginica', 'setosa'], columns=['pred_target'])\n",
    "pd.concat([new_obs, pred_target], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what K-Nearest Neighbors is doing for us. Except it's using the distance formula to actually compute the distance and find the K sample/labeled observations with the shortest or minimum distances. Of those K samples, which species is most common? i.e. what is the mode of those neighbors? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Model\n",
    "\n",
    "**Evaluate on Out-of-Sample data**\n",
    "\n",
    "Compute the accuracy of the model when run on the validate dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Create a new notebook, `knn_model`, and work with the titanic dataset to answer the following: \n",
    "\n",
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "1. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "1. Print and clearly label the following:  Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "1. Run through steps 1-3 setting k to 10\n",
    "\n",
    "1. Run through steps 1-3 setting k to 20\n",
    "\n",
    "1. What are the differences in the evaluation metrics?  Which performs better on your in-sample data? Why?\n",
    "\n",
    "1. Which model performs best on our out-of-sample data from `validate`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

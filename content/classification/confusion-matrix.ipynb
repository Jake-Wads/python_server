{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Performance of Binary Classification Models\n",
    "\n",
    "I can barely 'RECALL'​ with enough 'PRECISION'​ and little 'SPECIFICITY'​ what is 'SENSITIVITY'​!\n",
    "Confusion Matrix\n",
    "https://www.linkedin.com/pulse/i-can-barely-recall-enough-precision-little-what-anurag-halder/\n",
    "\n",
    "Published on July 24, 2019\n",
    " Anurag Halder\n",
    "Anurag Halder\n",
    "Intrigued by Machine Learning - Deep Learning | Computer Vision | Fon... See mor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "- Confusion Matrix\n",
    "- Sensitivity\n",
    "- Specificity\n",
    "- Precision\n",
    "- Recall\n",
    "- True/False Positive\n",
    "- True/False Negative\n",
    "- Type I Error\n",
    "- Type II Error\n",
    "- ROC: Receiver Operator Curve\n",
    "- AUC: Area Under Curve\n",
    "\n",
    "The output of the classification model should be probabilities (not absolute values of 0 or 1)\n",
    "\n",
    "Look at the Confusion Matrix: \n",
    "- The outcome of a confusion matrix being 'given a chosen threshold' the counts of 1's actually predicted as 1's (true positives), the count of 0's actually predicted as 0's (true negatives)\n",
    "- This leads to a lower misclassification rate...predicting the 1's as 0's (false negative) and the 0's as 1's (false positives)\n",
    "- We need to know how to arrive at the optimal threshold\n",
    "- Note: Positive or Negative is a nomenclature, you can choose to select one of your classes as positive while the other class as negative. Example, in a classification between 2 types of cars, say audi and volvo, you may assign volve as the positive class and audi as negative and vice versa.\n",
    "\n",
    "Plot some histograms: \n",
    "- Plot a blue density curve of the actual negatives (0's) with the predicted probabilities\n",
    "- On top of that, plot a red the density curve of the actual positives (1's) with the predicted probabilities\n",
    "- The curves should look well separated with marginal overlap\n",
    "\n",
    "Choosing an optimal threshold:\n",
    "\n",
    "- True Positive Rate: How many actual positive class examples where correctly predicted as positive. True Positive / (Actual Positives = True Positive + False Negative)\n",
    "- False Positive Rate: how many of the actual Negative class examples got classified into Positive class. False Positive / (Total Negatives = False Positive + True Negative)\n",
    "- Misclassification Rate: the ratio of all the cases which were incorrectly classified of all the observations. (False Positive + False Negative) / (Number of examples). \n",
    "- We are choosing a starting threshold of 0 and then evaluating our confusion matrix, i.e. the red line in our histogram is at the extreme left, hence by the blue curve (Negative class) lying to the right of the threshold, all actual Negative class examples have been classified as positive, i.e. 100% False Positive Rate\n",
    "- Similarly by the Red Curve (Positive class) all the actual positives have been classified as positives thus a 100% True Positive Rate. This continues till the threshold line (red line) enters the blue curve. \n",
    "\n",
    "Lets for simplicity break the problem into different zones the threshold line can fall on.\n",
    "\n",
    "- Zone 1: Till the threshold touches the blue curve - False Positive Rate and True Positive Rate are 100% as explained above\n",
    "\n",
    "- Zone 2: Till the threshold is in the blue curve but before the red curve - Now some of the actual Negative class examples have started falling to the left of the threshold so misclassification of the negative class is reducing hence False Positive Rate will start to go down from 100% but because the red curve or the positive class is still to the right it continues to be at 100% True Positive Rate\n",
    "\n",
    "- Zone 3: When the threshold is in the intersecting zone - Here now some of the positive class has started to lie on the left hand side causing misclassfication of the positive class. From the blue curve perspective we are more and more classifying negatives as negatives now and hence False Positive Rate is steeply dropping while more of the red curve now falling left resulting in True Positive Rate to go down from 100%\n",
    "\n",
    "- Zone 4: Till the threshold is in the red curve - At this stage all negatives class examples have been classified as negative so False Positive Rate has touched 0% while as the threshold moves towards the right tail of the red curve it is more and more misclassfiying the positive class as negative causing a steep drop of True Positive Rate towards 0%\n",
    "\n",
    "- Zone 5: When the threshold is beyond the red curve - At this point all negative class (blue curve) examples have been classified as negative hence False Positive Rate is at 0% while all positive class examples (red curve) have been misclassified into the negative class i.e. True Positive Rate is also at 0%\n",
    "\n",
    "- All the Zones explained above when put together in a graph they result in ROC or Receiver Operator Curve. By looking at the Receiver Operator Curve and by calculating the area below it you will be able to establish how well your model is able to classify between different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example: Want to find the probability of disease given a positive test, $P(D|+)$, and we have the probability of a positive test given disease, $P(+|D)$\n",
    "    \n",
    "- **Sensitivity** $P(+|D)$: probability of positive test given disease\n",
    "- **Specificity** $P(-|D^c)$: probability of negative test given no disease\n",
    "- **Positive Predictive Value** $P(D|+)$: probability of disease given positive test\n",
    "- **Negative Predictive Value** $P(D^c|-)$: probability of no disease given negative test\n",
    "- **Prevalence** $P(D)$: probability in absence of a test\n",
    "\n",
    "The diagnostic **likelihood** of having the disease\n",
    "\n",
    "$$\\frac{P(+|D)}{P(+|D^c)}$$\n",
    "\n",
    "The **odds**\n",
    "\n",
    "$$\\frac{P(D)}{P(D^c)}$$\n",
    "\n",
    "The **post-test odds** of disease is the product of diagnostic likelihood and odds:\n",
    "\n",
    "$$\\frac{P(D|+)}{P(D^c|+)} = \\frac{P(+|D)}{P(+|D^c)} * \\frac{P(D)}{P(D^c)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors:\n",
    "\n",
    "#### Type I Error\n",
    "\n",
    "- False Positive: Reject the null hypothesis when there is in fact no significant effect.\n",
    "\n",
    "- Exmaple 1: I am rejecting the hypothesis that there is no significant difference in price from those in their 4th year to those in their 1st year. i.e. there is a significant difference (over-generalization and will make statisticians cringe, but if you think of it that way, I won't reprimand you ;))  But in a type I error, it turns out, there is actually is no difference in the 2 populations.  It was just by chance that my two samples showed a difference.\n",
    "\n",
    "- Example 2: I am rejecting the hypothesis that tenure and monthly price are independent of each other (i.e. I think they are correlated).  But, in this type I error, it turns out that they are actually independent of each other, and the correlation I saw in my samples was just by chance.\n",
    "\n",
    "#### Type II Error\n",
    "\n",
    "- False Negative: Not reject the null hypothesis when there is a significant effect.\n",
    "\n",
    "- Exmaple 1: I 'fail to reject' the hypothesis that there is no significant difference in price from those in their 4th year to those in their 1st year. I.e. I don't find a significant effect in the 2 groups, when in actuality there is a difference in the 2 populations.  It was just by chance that my two samples did not show a difference.\n",
    "\n",
    "- Example 2: I 'fail to reject' the hypothesis that tenure and monthly price are independent of each other. I.e. I think they are not correlated with each other, when, in actuality, they are correlated with each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

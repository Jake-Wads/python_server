{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM: Support Vector Machine\n",
    "\n",
    "A hyperplane (line that splits the input variable space) is selected to best separate the points in the input variable space by their class, either class 0 or class 1. In two-dimensions, you can visualize this as a line.  An optimization algorithm is used to find the values for the coefficients that maximizes the margin.  The distance between the hyperplane and the closest data points is referred to as the **margin**. The best or optimal hyperplane that can separate the two classes is the line that has the largest margin. Only these points, called the **support vectors**, are relevant in defining the hyperplane and in the construction of the classifier.\n",
    "\n",
    "Pros | Cons\n",
    ":----|:----\n",
    "Effective in high dimensional spaces | Does not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation.  \n",
    "It works really well with clear margin of separation | Prone to overfitting   \n",
    "It is effective in cases where number of dimensions is greater than the number of samples. | Poor performance with a large data set because the required training time is higher.  \n",
    "Memory efficient | Poor performance with very noisy datasets, where the target classes are overlapping especially. \n",
    "Powerful out-of-the-box classifiers | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "`sklearn.svm.SVC(C=1.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False,tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None)`\n",
    "\n",
    "Parameters with higher impact on model performance:  “kernel”, “gamma” and “C”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels: a way to transform features\n",
    "\n",
    "Instead of being forced to live in a coordinate system such as <x0,⋯, x1>, we can instead transform our data into a new coordinate system that is easier to solve. \n",
    "\n",
    "(show plot of 2 circles, one inside the other): draw a straight line that separates the two circles.\n",
    "\n",
    "![svm_image1.png](svm_image1.png)\n",
    "\n",
    "These look like regular circles, so there doesn’t appear to be a line that you could separate them with. This is true in 2D Cartesian coordinate systems, but if you project this into a 3D Cartesian coordinate system, < x,y > → <x2,√2xy,y2>, you will find that in fact this turns out to be linear.  \n",
    "\n",
    "Now you can see that these two circles are separate and you can draw a plane easily between the two. If you took that and mapped it back to the original plane, then there would in fact be a third circle in the middle that is a straight plane.\" \n",
    "\n",
    "![svm_image2.png](svm_image2.png)\n",
    "\n",
    "As a side note, there are many different types of projections (or kernels) such as:\n",
    "\n",
    "- Polynomial kernel (heterogeneous and homogeneous)\n",
    "- Radial basis functions\n",
    "- Gaussian kernels\n",
    "\n",
    "Options avialable with sklearn.svm.SVC:\n",
    "\n",
    "- “linear”, “**rbf**”,”poly” and others  \n",
    "- “rbf” and “poly” are useful for non-linear hyper-plane.\n",
    "- look at the iris example, where we’ve used linear kernel on two feature of iris data set to classify their class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset('iris')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['species'],axis=1)\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01428155, 0.01439904, 0.97131941],\n",
       "       [0.0163127 , 0.00985372, 0.97383358],\n",
       "       [0.00757722, 0.95064107, 0.04178171],\n",
       "       [0.95145722, 0.02451949, 0.02402328],\n",
       "       [0.94195462, 0.02745419, 0.03059119],\n",
       "       [0.01615358, 0.17168914, 0.81215728],\n",
       "       [0.93045699, 0.04387476, 0.02566825],\n",
       "       [0.94782817, 0.0276442 , 0.02452763],\n",
       "       [0.01337596, 0.93357643, 0.05304762],\n",
       "       [0.00980796, 0.94920915, 0.04098289]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(probability = True, random_state = 123)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_train)\n",
    "y_pred_proba = svm.predict_proba(X_train)\n",
    "y_pred_proba[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "      .format(svm.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[32  0  0]\n",
      " [ 0 39  1]\n",
      " [ 0  1 32]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix\\n',confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        32\n",
      "  versicolor       0.97      0.97      0.97        40\n",
      "   virginica       0.97      0.97      0.97        33\n",
      "\n",
      "    accuracy                           0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Resources for SVM\n",
    "\n",
    "- [SKLearn Example SVM](https://scikit-learn.org/stable/auto_examples/exercises/plot_iris_exercise.html#sphx-glr-auto-examples-exercises-plot-iris-exercise-py)\n",
    "- [Support Vector Machines: A Visual Explanation with Sample Python Code](https://www.youtube.com/watch?v=N1vOgolbjSc)\n",
    "- [Muffin vs. Cupcake SVM Classification example code](https://github.com/adashofdata/muffin-cupcake)\n",
    "- [SVM Deep dive on turning decision boundaries into decision rules](https://www.youtube.com/watch?v=_PwhiWxHK8o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Write a function to train, predict, and evaluate an SVM classifier. \n",
    "In your function, add a 'kernel' argument so that you can then run the function multiple times with different values for the kernel and compare results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

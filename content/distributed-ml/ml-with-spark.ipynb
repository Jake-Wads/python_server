{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Spark\n",
    "\n",
    "In this lesson we'll take a look at how to implement and evaluate machine learning models with spark.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First we'll do a couple of imports and setup our spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pydataset import data\n",
    "\n",
    "import pyspark\n",
    "import pyspark.ml\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we'll use for this lesson is the `swiss` dataset. We'll cleanup the column names just a bit before we turn the dataset into a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+---------+--------+----------------+\n",
      "|fertility|agriculture|examination|education|catholic|infant_mortality|\n",
      "+---------+-----------+-----------+---------+--------+----------------+\n",
      "|     80.2|       17.0|         15|       12|    9.96|            22.2|\n",
      "|     83.1|       45.1|          6|        9|   84.84|            22.2|\n",
      "|     92.5|       39.7|          5|        5|    93.4|            20.2|\n",
      "|     85.8|       36.5|         12|        7|   33.77|            20.3|\n",
      "|     76.9|       43.5|         17|       15|    5.16|            20.6|\n",
      "+---------+-----------+-----------+---------+--------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swiss = data(\"swiss\")\n",
    "swiss.columns = [col.lower().replace(\".\", \"_\") for col in swiss]\n",
    "swiss = spark.createDataFrame(swiss)\n",
    "swiss.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "We'll first take a look at implementing a classification model. In order to do so, we'll need a categorical variable to predict. We'll transform the `catholic` column into a categorical variable indicating whether a province is catholic or not.\n",
    "\n",
    "First we'll plot a histogram to justify why this transformation is reasonable to make:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x121661b38>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "swiss.toPandas().catholic.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization above tells us that most provinces fall into on of two extremes in regards to percentage catholic.\n",
    "\n",
    "We'll now go ahead and use spark to make the transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+---------+----------------+------------+\n",
      "|fertility|agriculture|examination|education|infant_mortality| is_catholic|\n",
      "+---------+-----------+-----------+---------+----------------+------------+\n",
      "|     80.2|       17.0|         15|       12|            22.2|Not Catholic|\n",
      "|     83.1|       45.1|          6|        9|            22.2|    Catholic|\n",
      "|     92.5|       39.7|          5|        5|            20.2|    Catholic|\n",
      "|     85.8|       36.5|         12|        7|            20.3|Not Catholic|\n",
      "|     76.9|       43.5|         17|       15|            20.6|Not Catholic|\n",
      "+---------+-----------+-----------+---------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swiss = swiss.withColumn(\n",
    "    \"is_catholic\",\n",
    "    when(swiss.catholic > 60, \"Catholic\").otherwise(\"Not Catholic\"),\n",
    ").drop(\"catholic\")\n",
    "swiss.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Our Data For Machine Learning\n",
    "\n",
    "Spark's machine learning library requires that our data be in a very specific format. A dataframe that will be used with one of spark's machine learning models must have one column (`features`) that contains a list of the independent variable values, and another column (`label`) that contains the target variable. In addition, all numbers must be floats. Luckily, spark supplies us with some functionality to make this transformation pretty easy.\n",
    "\n",
    "Within the `pyspark.ml.feature` module are many classes that perform different transformations on dataframes, for example, min-max scaling. We'll take a look at the `RFormula` class, which we can use to quickly transform our data into the necessary format.\n",
    "\n",
    "!!!note \"Other Transformations With Spark\"\n",
    "    We are just exploring the `RFormula` class in this lesson, but the `pyspark.ml.feature` module contains many more classess as well, for things like scaling numeric features, or extracting tokens from text.\n",
    "\n",
    "The way we work with this class is similar to how we work with the `sklearn` classes, in that we'll first need to fit the object, then transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "rf = RFormula(formula=\"is_catholic ~ agriculture + examination\")\n",
    "\n",
    "df = rf.fit(swiss).transform(swiss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specified a string containing a formula that describes a linear model to be fit. This formula is taken from the R programming langauge. Here are several examples:\n",
    "\n",
    "- `y ~ x`: predict `y` based on `x`\n",
    "- `y ~ x1 + x2 + x3`: predict `y` based on `x1`, `x2`, and `x3`\n",
    "- `y ~ .`: predict `y` based on all of the variables except for the independent variable (i.e. everything except for `y`)\n",
    "\n",
    "In our case, we wrote a formula to predict `is_catholic` based on `agriculture` and `examination`.\n",
    "\n",
    "The `RFormula` object will add two new columns to our data frame, `features`, and `label`, and we'll store those in `df` so that we can feed them into a Logistic Regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+---------+----------------+------------+-----------+-----+\n",
      "|fertility|agriculture|examination|education|infant_mortality| is_catholic|   features|label|\n",
      "+---------+-----------+-----------+---------+----------------+------------+-----------+-----+\n",
      "|     80.2|       17.0|         15|       12|            22.2|Not Catholic|[17.0,15.0]|  0.0|\n",
      "|     83.1|       45.1|          6|        9|            22.2|    Catholic| [45.1,6.0]|  1.0|\n",
      "|     92.5|       39.7|          5|        5|            20.2|    Catholic| [39.7,5.0]|  1.0|\n",
      "|     85.8|       36.5|         12|        7|            20.3|Not Catholic|[36.5,12.0]|  0.0|\n",
      "|     76.9|       43.5|         17|       15|            20.6|Not Catholic|[43.5,17.0]|  0.0|\n",
      "+---------+-----------+-----------+---------+----------------+------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've imported the `LogisticRegression` class, we can make an instance of it, and use the `.fit` method to get a fitted model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_1bc73b0acb59, numClasses = 2, numFeatures = 2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "# lr.explainParams() # to show all of the hyperparams\n",
    "lr_fit = lr.fit(df)\n",
    "lr_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.transform` method can be used to make predictions with our model. The data we give to the `.transform` method needs to be in the same shape that we used for training the model.\n",
    "\n",
    "We'll also add a column named `we_got_it_right`, which is boolean value that indicates whether or not our prediction was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+--------------------+--------------------+----------+---------------+\n",
      "| is_catholic|label|       rawPrediction|         probability|prediction|we_got_it_right|\n",
      "+------------+-----+--------------------+--------------------+----------+---------------+\n",
      "|Not Catholic|  0.0|[2.61081360006245...|[0.93155429036120...|       0.0|           true|\n",
      "|    Catholic|  1.0|[-1.9844861732885...|[0.12084142107894...|       1.0|           true|\n",
      "|    Catholic|  1.0|[-2.1417946363626...|[0.10510047647313...|       1.0|           true|\n",
      "|Not Catholic|  0.0|[0.65897957038476...|[0.65903112585454...|       0.0|           true|\n",
      "|Not Catholic|  0.0|[2.27460235659845...|[0.90675166037879...|       0.0|           true|\n",
      "+------------+-----+--------------------+--------------------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    lr_fit.transform(df)\n",
    "    .withColumn(\"we_got_it_right\", col(\"label\") == col(\"prediction\"))\n",
    "    .select(\n",
    "        \"is_catholic\",\n",
    "        \"label\",\n",
    "        \"rawPrediction\",\n",
    "        \"probability\",\n",
    "        \"prediction\",\n",
    "        \"we_got_it_right\",\n",
    "    )\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our model's performance, we can take a look at the `summary` property of the fit model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary at 0x1217a1240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary = lr_fit.summary\n",
    "training_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This summary contains many properties that are common classification metrics. Several examples are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9314516129032258"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723404255319149"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9354838709677419, 0.75]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.recallByLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8787878787878788, 0.8571428571428571]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.precisionByLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Building a regression model will follow the same pattern as building the classification model.\n",
    "\n",
    "For this example, we'll try to predict `fertility` based on `education` and `examination`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+---------+----------------+------------+\n",
      "|fertility|agriculture|examination|education|infant_mortality| is_catholic|\n",
      "+---------+-----------+-----------+---------+----------------+------------+\n",
      "|     80.2|       17.0|         15|       12|            22.2|Not Catholic|\n",
      "|     83.1|       45.1|          6|        9|            22.2|    Catholic|\n",
      "|     92.5|       39.7|          5|        5|            20.2|    Catholic|\n",
      "|     85.8|       36.5|         12|        7|            20.3|Not Catholic|\n",
      "|     76.9|       43.5|         17|       15|            20.6|Not Catholic|\n",
      "|     76.1|       35.3|          9|        7|            26.6|    Catholic|\n",
      "|     83.8|       70.2|         16|        7|            23.6|    Catholic|\n",
      "|     92.4|       67.8|         14|        8|            24.9|    Catholic|\n",
      "|     82.4|       53.3|         12|        7|            21.0|    Catholic|\n",
      "|     82.9|       45.2|         16|       13|            24.4|    Catholic|\n",
      "|     87.1|       64.5|         14|        6|            24.5|    Catholic|\n",
      "|     64.1|       62.0|         21|       12|            16.5|Not Catholic|\n",
      "|     66.9|       67.5|         14|        7|            19.1|Not Catholic|\n",
      "|     68.9|       60.7|         19|       12|            22.7|Not Catholic|\n",
      "|     61.7|       69.3|         22|        5|            18.7|Not Catholic|\n",
      "|     68.3|       72.6|         18|        2|            21.2|Not Catholic|\n",
      "|     71.7|       34.0|         17|        8|            20.0|Not Catholic|\n",
      "|     55.7|       19.4|         26|       28|            20.2|Not Catholic|\n",
      "|     54.3|       15.2|         31|       20|            10.8|Not Catholic|\n",
      "|     65.1|       73.0|         19|        9|            20.0|Not Catholic|\n",
      "+---------+-----------+-----------+---------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swiss.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we'll use the `RFormula` object to transform our data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   features|label|\n",
      "+-----------+-----+\n",
      "|[12.0,15.0]| 80.2|\n",
      "|  [9.0,6.0]| 83.1|\n",
      "|  [5.0,5.0]| 92.5|\n",
      "| [7.0,12.0]| 85.8|\n",
      "|[15.0,17.0]| 76.9|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RFormula(formula=\"fertility ~ education + examination\")\n",
    "\n",
    "df = rf.fit(swiss).transform(swiss).select(\"features\", \"label\")\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then feed the data into a spark machine learning model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------------------+\n",
      "|   features|label|        prediction|\n",
      "+-----------+-----+------------------+\n",
      "|[12.0,15.0]| 80.2| 70.42151794297949|\n",
      "|  [9.0,6.0]| 83.1| 77.05485310331397|\n",
      "|  [5.0,5.0]| 92.5| 79.76989921395027|\n",
      "| [7.0,12.0]| 85.8|  74.7904575219264|\n",
      "|[15.0,17.0]| 76.9| 67.68871054525117|\n",
      "|  [7.0,9.0]| 76.1| 76.46211227732904|\n",
      "| [7.0,16.0]| 83.8| 72.56158451472288|\n",
      "| [8.0,14.0]| 92.4| 73.13656405361579|\n",
      "| [7.0,12.0]| 82.4|  74.7904575219264|\n",
      "|[13.0,16.0]| 82.9| 69.32484272646975|\n",
      "| [6.0,14.0]| 87.1|  74.2154779830335|\n",
      "|[12.0,21.0]| 64.1| 67.07820843217421|\n",
      "| [7.0,14.0]| 66.9| 73.67602101832463|\n",
      "|[12.0,19.0]| 68.9| 68.19264493577597|\n",
      "| [5.0,22.0]| 61.7| 70.29718893333529|\n",
      "| [2.0,18.0]| 68.3| 74.14443283466538|\n",
      "| [8.0,17.0]| 71.7| 71.46490929821314|\n",
      "|[28.0,26.0]| 55.7|55.660805737828156|\n",
      "|[20.0,31.0]| 54.3| 57.19037019649457|\n",
      "| [9.0,19.0]| 65.1| 69.81101582990253|\n",
      "+-----------+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr_fit = lr.fit(df)\n",
    "lr_fit.transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the logistic regression model, we have access to a `summary` property that gives us common regression model evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_summary = lr_fit.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5054845186373226, 8.69043227803294)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.r2, training_summary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.223147119974515, 75.52361317907679)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_summary.meanAbsoluteError, training_summary.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         residuals|\n",
      "+------------------+\n",
      "| 9.778482057020511|\n",
      "|6.0451468966860205|\n",
      "|12.730100786049732|\n",
      "|11.009542478073598|\n",
      "| 9.211289454748837|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_summary.residuals.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "- [Spark's Machine Learning Guide](https://spark.apache.org/docs/latest/ml-guide.html)\n",
    "- [Regression and Classification with Spark](https://spark.apache.org/docs/latest/ml-classification-regression.html)\n",
    "- [Extracting, Transforming, and Selecting Features](https://spark.apache.org/docs/latest/ml-features.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Remember to drop your nulls!** Be 100% sure to remove any and all nulls from your data. As with any machine learning, the algorithms won't work. But the error messages from Spark when you have nulls don't say \"Remove your nulls\". They will be extra obscure, so *remove all nulls*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Do your work for theses exercises in a jupyter notebook or python script named `model`.\n",
    "\n",
    "1. Use the `.randomSplit` method to split the 311 data into training and test\n",
    "   sets.\n",
    "1. Create a classification model to predict whether a case will be late or not\n",
    "   (i.e. predict `case_late`). Experiment with different combinations of\n",
    "   features and different classification algorithms.\n",
    "1. Create a regression model to predict how many days late a case will be\n",
    "   (i.e. predict `num_days_late`). Experiment with different combinations of\n",
    "   features and different regression algorithms."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9eaa35-6494-4963-9090-0e5b5c116a69",
   "metadata": {},
   "source": [
    "## kNN Exercises\n",
    "Create a new notebook, `knn_model`, and work with the `titanic` dataset to answer the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a9525-bf62-4ddb-b460-feffb3d434f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import acquire\n",
    "from prepare import prep_titanic_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b0fb9-3585-44ff-8065-113f4cb8d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "# prepare the data\n",
    "train, validate, test = prep_titanic_data(df)\n",
    "\n",
    "# drop object columns and create X_train of features only \n",
    "# and y_train of survived only. \n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived\n",
    "\n",
    "# check the shape\n",
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c533a-093b-49d1-a0ab-22fba5923680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f304cd-9104-494e-b7a3-4550b4a11df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976eea0-7f41-4367-a47d-16c20f16ca4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write a function to compute the baseline for a classification model\n",
    "\n",
    "def establish_baseline(y_train):\n",
    "    #  establish the value we will predict for all observations\n",
    "    baseline_prediction = y_train.mode()\n",
    "\n",
    "    # create a series of predictions with that value, \n",
    "    # the same length as our training set\n",
    "    y_train_pred = pd.Series((baseline_prediction[0]), range(len(y_train)))\n",
    "\n",
    "    # compute accuracy of baseline\n",
    "    cm = confusion_matrix(y_train, y_train_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697ab27-f0fe-4ca0-9c65-44561c424ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d074a78-3623-4f85-ac63-4aec831ea3c8",
   "metadata": {},
   "source": [
    "# 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fa7d1-71aa-4291-a1c8-5b9ecf377a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE the thing\n",
    "\n",
    "\n",
    "# FIT the thing\n",
    "\n",
    "\n",
    "# USE the thing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec02577-4b8a-4f5a-bd5f-53e2808bbeee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780a4cd-d849-4285-b5bd-ed785d129fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the accuracy score of train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa4e80-a39d-4e2a-b769-d27216691e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a18ae-a0cb-4178-8e54-8ed7dc69f621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824598e-a31c-4e0f-be9d-2d75be1b87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8889f6b8-514f-4c64-bef8-ac2eb4e3b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report as df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a829a6-21d3-48f4-9f6d-42158b67a6ff",
   "metadata": {},
   "source": [
    "# 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1163e94-cbed-47e2-bfab-60bbc3322dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = \n",
    "\n",
    "accuracy = (\n",
    "\n",
    "true_positive_rate = \n",
    "false_positive_rate =\n",
    "true_negative_rate = \n",
    "false_negative_rate =\n",
    "\n",
    "precision = \n",
    "recall = \n",
    "f1_score = \n",
    "\n",
    "support_pos = \n",
    "support_neg = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ff97a1-3dcf-410a-8540-4d08a51b9bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeee3c5-49cf-4a98-91bf-4aef9180a4dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_cm_metrics(cm):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = (tp + tn)/(tn + fp + fn + tp)\n",
    "\n",
    "    true_positive_rate = tp/(tp + fn)\n",
    "    false_positive_rate = fp/(fp + tn)\n",
    "    true_negative_rate = tn/(tn + fp)\n",
    "    false_negative_rate = fn/(fn + tp)\n",
    "\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    f1_score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "    support_pos = tp + fn\n",
    "    support_neg = fp + tn\n",
    "\n",
    "    dict = {\n",
    "        'metric' : ['accuracy'\n",
    "                    ,'true_positive_rate'\n",
    "                    ,'false_positive_rate'\n",
    "                    ,'true_negative_rate'\n",
    "                    ,'false_negative_rate'\n",
    "                    ,'precision'\n",
    "                    ,'recall'\n",
    "                    ,'f1_score'\n",
    "                    ,'support_pos'\n",
    "                    ,'support_neg']\n",
    "        ,'score' : [accuracy\n",
    "                    ,true_positive_rate\n",
    "                    ,false_positive_rate\n",
    "                    ,true_negative_rate\n",
    "                    ,false_negative_rate\n",
    "                    ,precision\n",
    "                    ,recall\n",
    "                    ,f1_score\n",
    "                    ,support_pos\n",
    "                    ,support_neg]\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3037ada-fef6-485b-8e17-18490f944fc5",
   "metadata": {},
   "source": [
    "# 4. Run through steps 1-3 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655cf4d-c46a-4b55-84c3-da430861a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_fit_predict(k, X_train, y_train, X_validate):\n",
    "    '''\n",
    "    This function takes n_neighbors, X_train,  target  and X_val\n",
    "    and returns knn, predictions for train set and validate set\n",
    "    '''\n",
    "    # MAKE the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # FIT the thing\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # USE the thing\n",
    "    y_train_pred = knn.predict(X_train)\n",
    "    y_validate_pred = knn.predict(X_validate)\n",
    "    \n",
    "    return knn, y_train_pred, y_validate_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d65d9-ceea-45c6-b52a-10e2dcc54234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(model, X, y, y_pred):\n",
    "    '''\n",
    "    This function can be used on any classification model\n",
    "    It takes in a model, features, target and prediction\n",
    "    and returns the accuracy, confusion matrix and classification report\n",
    "    '''\n",
    "    # model score\n",
    "    accuracy = model.score(X, y)\n",
    "\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    cmdf = pd.DataFrame(cm, index=['Actual 0', 'Actual 1'], \n",
    "                       columns=['Pred 0', 'Pred 1'])\n",
    "\n",
    "    # classification report\n",
    "    crdf = pd.DataFrame(classification_report(y, y_pred, output_dict=True))\n",
    "    \n",
    "    # confusion matrix metrics\n",
    "    metrics = print_cm_metrics(cm)\n",
    "    \n",
    "    return accuracy, cmdf, crdf, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c007472-b9d8-4221-9f2d-1298c256ae25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02db4e-c4c9-43d4-b4cb-76af91c6b6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8da1620-da30-47ae-970d-d49a317dc64a",
   "metadata": {},
   "source": [
    "# 5. Run through steps 1-3 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e5804-97e9-486d-b76d-2ad2b5f95191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a87b0-594d-4193-9f4c-eb30723e5aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37af83c5-9ea2-4ef4-83db-fe3cab2ea40a",
   "metadata": {},
   "source": [
    "# 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab904b-9259-4316-bcef-b3ba2b651cc4",
   "metadata": {},
   "source": [
    "# 7. Which model performs best on our out-of-sample data from `validate`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560c9a4-abf5-4440-8057-ddac7ffe26ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaway:</b>\n",
    "    <br>\n",
    "Of the two k options (10 & 20) 10 nearest neighbors works best on the in-sample and out-of-sample data. However, the f1 score is better on the model where k = 20, so it is a bit more balanced. \n",
    "<br>  \n",
    "<br>\n",
    "BUT, let's loop through different K's and see what number of neighbors gives us the best results. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006c0e5-9ca8-4c92-8e1c-4a538c8f5194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc58d5a-e66b-45b7-9c4d-be7f9f9d126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.plot(eval_df.k, eval_df.train_accuracy, label='Train Accuracy')\n",
    "plt.plot(eval_df.k, eval_df.validate_accuracy, label='Validate Accuracy')\n",
    "plt.plot(eval_df.k, eval_df.difference, label='Accuracy Difference')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc2d49-f269-4e52-83bc-2cf417e1176c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Takeaway:</b>\n",
    "    <br>\n",
    "Looking at this chart, I would select k=12 as the best model, as the difference is closest to zero.\n",
    "    </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from os import path\n",
    "\n",
    "def get_article_text():\n",
    "    # if we already have the data, read it locally\n",
    "    if path.exists('article.txt'):\n",
    "        with open('article.txt') as f:\n",
    "            return f.read()\n",
    "\n",
    "    # otherwise go fetch the data\n",
    "    url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "    headers = {'User-Agent': 'Codeup Ada Data Science'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    article = soup.find('div', class_='mk-single-content')\n",
    "\n",
    "    # save it for next time\n",
    "    with open('article.txt', 'w') as f:\n",
    "        f.write(article.text)\n",
    "\n",
    "    return article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import re\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "seed=123\n",
    "\n",
    "# df = pd.read_csv('spam.csv')\n",
    "colnames = ['label','SMS']\n",
    "df = pd.read_csv('spam.csv', skiprows=1, names=colnames, \n",
    "                 encoding='latin-1', usecols=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(747, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>ham</td>\n",
       "      <td>Good. No swimsuit allowed :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>spam</td>\n",
       "      <td>Urgent! call 09066350750 from your landline. Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>ham</td>\n",
       "      <td>Im sorry bout last nite it wasnåÕt ur fault it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>spam</td>\n",
       "      <td>+123 Congratulations - in this week's competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wish i were with you now!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                                SMS\n",
       "3237   ham                       Good. No swimsuit allowed :)\n",
       "843   spam  Urgent! call 09066350750 from your landline. Y...\n",
       "3521   ham  Im sorry bout last nite it wasnåÕt ur fault it...\n",
       "2123  spam  +123 Congratulations - in this week's competit...\n",
       "738    ham                          Wish i were with you now!"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_extraction(msg):\n",
    "    # converting messages to lowercase\n",
    "    msg = msg.lower()\n",
    "    msg = re.sub('[^a-z]+', ' ', msg).split()\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing text messages\n",
    "df['word_list'] = df['SMS'].apply(word_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>word_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>ham</td>\n",
       "      <td>Good. No swimsuit allowed :)</td>\n",
       "      <td>[good, no, swimsuit, allowed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>spam</td>\n",
       "      <td>Urgent! call 09066350750 from your landline. Y...</td>\n",
       "      <td>[urgent, call, from, your, landline, your, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>ham</td>\n",
       "      <td>Im sorry bout last nite it wasnåÕt ur fault it...</td>\n",
       "      <td>[im, sorry, bout, last, nite, it, wasn, t, ur,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>spam</td>\n",
       "      <td>+123 Congratulations - in this week's competit...</td>\n",
       "      <td>[congratulations, in, this, week, s, competiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wish i were with you now!</td>\n",
       "      <td>[wish, i, were, with, you, now]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                                SMS  \\\n",
       "3237   ham                       Good. No swimsuit allowed :)   \n",
       "843   spam  Urgent! call 09066350750 from your landline. Y...   \n",
       "3521   ham  Im sorry bout last nite it wasnåÕt ur fault it...   \n",
       "2123  spam  +123 Congratulations - in this week's competit...   \n",
       "738    ham                          Wish i were with you now!   \n",
       "\n",
       "                                              word_list  \n",
       "3237                      [good, no, swimsuit, allowed]  \n",
       "843   [urgent, call, from, your, landline, your, com...  \n",
       "3521  [im, sorry, bout, last, nite, it, wasn, t, ur,...  \n",
       "2123  [congratulations, in, this, week, s, competiti...  \n",
       "738                     [wish, i, were, with, you, now]  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(word_lists):\n",
    "    words = []\n",
    "    for word_list in word_lists:\n",
    "        words.extend(word_list)\n",
    "    words = sorted(list(set(words)))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aaooooright',\n",
       " 'aathi',\n",
       " 'abiola',\n",
       " 'able',\n",
       " 'about',\n",
       " 'absolutely',\n",
       " 'abt',\n",
       " 'abta',\n",
       " 'ac',\n",
       " 'acc',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accidentally',\n",
       " 'account',\n",
       " 'achan',\n",
       " 'ache',\n",
       " 'acknowledgement',\n",
       " 'acnt',\n",
       " 'across',\n",
       " 'actin',\n",
       " 'activate',\n",
       " 'activities',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'added',\n",
       " 'address',\n",
       " 'admirer',\n",
       " 'admit',\n",
       " 'adp',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'ae',\n",
       " 'affairs',\n",
       " 'afraid',\n",
       " 'aft',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftr',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'agalla',\n",
       " 'age',\n",
       " 'ago',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahold',\n",
       " 'aight',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'aiyah',\n",
       " 'alaipayuthe',\n",
       " 'alertfrom',\n",
       " 'algorithms',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allah',\n",
       " 'allowed',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'alrite',\n",
       " 'also',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'ambrith',\n",
       " 'amk',\n",
       " 'amla',\n",
       " 'amma',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amt',\n",
       " 'amused',\n",
       " 'an',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'angry',\n",
       " 'animation',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'another',\n",
       " 'ans',\n",
       " 'answer',\n",
       " 'answers',\n",
       " 'antha',\n",
       " 'anti',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyones',\n",
       " 'anythin',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apartment',\n",
       " 'apnt',\n",
       " 'apologetic',\n",
       " 'apologize',\n",
       " 'app',\n",
       " 'applebees',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'approaching',\n",
       " 'aq',\n",
       " 'ar',\n",
       " 'ard',\n",
       " 'are',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'armand',\n",
       " 'arms',\n",
       " 'arng',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arrive',\n",
       " 'arrow',\n",
       " 'arty',\n",
       " 'arul',\n",
       " 'arun',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ask',\n",
       " 'askd',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asleep',\n",
       " 'ass',\n",
       " 'assessment',\n",
       " 'assume',\n",
       " 'astoundingly',\n",
       " 'astronomer',\n",
       " 'at',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attracts',\n",
       " 'aunty',\n",
       " 'auto',\n",
       " 'available',\n",
       " 'ave',\n",
       " 'avent',\n",
       " 'await',\n",
       " 'award',\n",
       " 'awarded',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'b',\n",
       " 'ba',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'babyjontet',\n",
       " 'back',\n",
       " 'backdoor',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'badly',\n",
       " 'bags',\n",
       " 'bajarangabali',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'baller',\n",
       " 'bandages',\n",
       " 'bar',\n",
       " 'bari',\n",
       " 'based',\n",
       " 'bash',\n",
       " 'basically',\n",
       " 'bat',\n",
       " 'bathe',\n",
       " 'battery',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bcaz',\n",
       " 'bcm',\n",
       " 'bcoz',\n",
       " 'bday',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beautiful',\n",
       " 'becaus',\n",
       " 'because',\n",
       " 'becomes',\n",
       " 'becoz',\n",
       " 'bed',\n",
       " 'bedrm',\n",
       " 'beehoon',\n",
       " 'been',\n",
       " 'befor',\n",
       " 'before',\n",
       " 'begging',\n",
       " 'behind',\n",
       " 'bein',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'bellearlier',\n",
       " 'belly',\n",
       " 'beneath',\n",
       " 'beside',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'bettersn',\n",
       " 'between',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bhaji',\n",
       " 'bids',\n",
       " 'big',\n",
       " 'bill',\n",
       " 'billion',\n",
       " 'bills',\n",
       " 'bin',\n",
       " 'biola',\n",
       " 'birds',\n",
       " 'biro',\n",
       " 'birthdate',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'black',\n",
       " 'blackberry',\n",
       " 'blacko',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blessed',\n",
       " 'blessings',\n",
       " 'blog',\n",
       " 'bloo',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'bloomberg',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blue',\n",
       " 'bluetooth',\n",
       " 'bmw',\n",
       " 'boat',\n",
       " 'body',\n",
       " 'bold',\n",
       " 'bomb',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'booking',\n",
       " 'books',\n",
       " 'booty',\n",
       " 'bored',\n",
       " 'borrow',\n",
       " 'boss',\n",
       " 'bot',\n",
       " 'both',\n",
       " 'bother',\n",
       " 'bothering',\n",
       " 'bottle',\n",
       " 'bout',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boytoy',\n",
       " 'bp',\n",
       " 'bpo',\n",
       " 'break',\n",
       " 'breathe',\n",
       " 'breathing',\n",
       " 'brief',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'britney',\n",
       " 'bro',\n",
       " 'broad',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brothas',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brownies',\n",
       " 'bruce',\n",
       " 'bslvyl',\n",
       " 'bt',\n",
       " 'bubbletext',\n",
       " 'bud',\n",
       " 'buddys',\n",
       " 'budget',\n",
       " 'bullshit',\n",
       " 'buns',\n",
       " 'burger',\n",
       " 'burns',\n",
       " 'bus',\n",
       " 'buses',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'buttons',\n",
       " 'buy',\n",
       " 'buying',\n",
       " 'buzz',\n",
       " 'bw',\n",
       " 'bx',\n",
       " 'by',\n",
       " 'bye',\n",
       " 'c',\n",
       " 'cabin',\n",
       " 'cafe',\n",
       " 'cake',\n",
       " 'calculation',\n",
       " 'call',\n",
       " 'callcost',\n",
       " 'called',\n",
       " 'caller',\n",
       " 'callers',\n",
       " 'callertune',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'cam',\n",
       " 'camcorder',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'campus',\n",
       " 'can',\n",
       " 'canal',\n",
       " 'canary',\n",
       " 'cann',\n",
       " 'cant',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " 'cappuccino',\n",
       " 'caps',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardin',\n",
       " 'care',\n",
       " 'cared',\n",
       " 'career',\n",
       " 'careers',\n",
       " 'careful',\n",
       " 'cares',\n",
       " 'caring',\n",
       " 'carlie',\n",
       " 'carlos',\n",
       " 'cars',\n",
       " 'cartons',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cashed',\n",
       " 'cashto',\n",
       " 'casing',\n",
       " 'casting',\n",
       " 'catch',\n",
       " 'catching',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'cd',\n",
       " 'cds',\n",
       " 'celebrate',\n",
       " 'celebration',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'centre',\n",
       " 'cer',\n",
       " 'chain',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charts',\n",
       " 'chasing',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'chechi',\n",
       " 'check',\n",
       " 'checking',\n",
       " 'checkmate',\n",
       " 'cheer',\n",
       " 'cheers',\n",
       " 'chennai',\n",
       " 'chess',\n",
       " 'chez',\n",
       " 'chikku',\n",
       " 'child',\n",
       " 'childporn',\n",
       " 'childrens',\n",
       " 'chillaxin',\n",
       " 'chillin',\n",
       " 'chinatown',\n",
       " 'chinese',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'christmas',\n",
       " 'cinema',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'claypot',\n",
       " 'cld',\n",
       " 'clean',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'cleared',\n",
       " 'clearing',\n",
       " 'clever',\n",
       " 'click',\n",
       " 'clip',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'club',\n",
       " 'clubsaisai',\n",
       " 'cm',\n",
       " 'cncl',\n",
       " 'co',\n",
       " 'coca',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'coincidence',\n",
       " 'cola',\n",
       " 'cold',\n",
       " 'collages',\n",
       " 'colleagues',\n",
       " 'collect',\n",
       " 'collected',\n",
       " 'collecting',\n",
       " 'collection',\n",
       " 'colleg',\n",
       " 'colour',\n",
       " 'colours',\n",
       " 'com',\n",
       " 'comb',\n",
       " 'combine',\n",
       " 'come',\n",
       " 'comedy',\n",
       " 'comes',\n",
       " 'comin',\n",
       " 'coming',\n",
       " 'command',\n",
       " 'commercial',\n",
       " 'community',\n",
       " 'comp',\n",
       " 'company',\n",
       " 'competition',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complimentary',\n",
       " 'comprehensive',\n",
       " 'computer',\n",
       " 'comuk',\n",
       " 'concentrate',\n",
       " 'conditions',\n",
       " 'confidence',\n",
       " 'confirm',\n",
       " 'confused',\n",
       " 'congrats',\n",
       " 'congratulations',\n",
       " 'connection',\n",
       " 'cons',\n",
       " 'consistently',\n",
       " 'constant',\n",
       " 'contact',\n",
       " 'contents',\n",
       " 'control',\n",
       " 'conversations',\n",
       " 'converted',\n",
       " 'convey',\n",
       " 'conveying',\n",
       " 'convinced',\n",
       " 'cookies',\n",
       " 'cool',\n",
       " 'coping',\n",
       " 'copy',\n",
       " 'cornwall',\n",
       " 'corrct',\n",
       " 'correct',\n",
       " 'correction',\n",
       " 'correctly',\n",
       " 'cos',\n",
       " 'cosign',\n",
       " 'cost',\n",
       " 'costs',\n",
       " 'couch',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'coupla',\n",
       " 'couple',\n",
       " 'courage',\n",
       " 'course',\n",
       " 'covers',\n",
       " 'coz',\n",
       " 'cr',\n",
       " 'crab',\n",
       " 'crammed',\n",
       " 'crashed',\n",
       " 'crave',\n",
       " 'crazy',\n",
       " 'created',\n",
       " 'creative',\n",
       " 'credit',\n",
       " 'credited',\n",
       " 'credits',\n",
       " 'creep',\n",
       " 'cricketer',\n",
       " 'cried',\n",
       " 'crucify',\n",
       " 'cs',\n",
       " 'csbcm',\n",
       " 'cud',\n",
       " 'cuddled',\n",
       " 'cuddling',\n",
       " 'cultures',\n",
       " 'cum',\n",
       " 'custcare',\n",
       " 'customer',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cuz',\n",
       " 'cw',\n",
       " 'cya',\n",
       " 'd',\n",
       " 'da',\n",
       " 'dabbles',\n",
       " 'dad',\n",
       " 'dammit',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'dancin',\n",
       " 'dane',\n",
       " 'dao',\n",
       " 'dark',\n",
       " 'darker',\n",
       " 'darkest',\n",
       " 'darlin',\n",
       " 'darren',\n",
       " 'dasara',\n",
       " 'dat',\n",
       " 'date',\n",
       " 'dating',\n",
       " 'dave',\n",
       " 'dawns',\n",
       " 'day',\n",
       " 'days',\n",
       " 'daywith',\n",
       " 'db',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'dealer',\n",
       " 'dealing',\n",
       " 'dear',\n",
       " 'dearer',\n",
       " 'dearly',\n",
       " 'december',\n",
       " 'decided',\n",
       " 'decimal',\n",
       " 'deepest',\n",
       " 'defeat',\n",
       " 'definite',\n",
       " 'delivered',\n",
       " 'delivery',\n",
       " 'dem',\n",
       " 'demand',\n",
       " 'den',\n",
       " 'depends',\n",
       " 'depressed',\n",
       " 'derek',\n",
       " 'description',\n",
       " 'desparately',\n",
       " 'desperate',\n",
       " 'despite',\n",
       " 'destination',\n",
       " 'detail',\n",
       " 'details',\n",
       " 'devouring',\n",
       " 'dha',\n",
       " 'dhoni',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'didnt',\n",
       " 'didntgive',\n",
       " 'died',\n",
       " 'difficult',\n",
       " 'dificult',\n",
       " 'digi',\n",
       " 'digital',\n",
       " 'din',\n",
       " 'ding',\n",
       " 'dinner',\n",
       " 'dint',\n",
       " 'direct',\n",
       " 'directly',\n",
       " 'dirty',\n",
       " 'dis',\n",
       " 'disclose',\n",
       " 'discount',\n",
       " 'distance',\n",
       " 'disturb',\n",
       " 'diwali',\n",
       " 'dload',\n",
       " 'dnt',\n",
       " 'do',\n",
       " 'dock',\n",
       " 'doctor',\n",
       " 'dodda',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doesnt',\n",
       " 'doggin',\n",
       " 'dogging',\n",
       " 'dogs',\n",
       " 'doin',\n",
       " 'doinat',\n",
       " 'doing',\n",
       " 'dokey',\n",
       " 'dollars',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'dorm',\n",
       " 'dormitory',\n",
       " 'double',\n",
       " 'dough',\n",
       " 'down',\n",
       " 'download',\n",
       " 'downstem',\n",
       " 'dps',\n",
       " 'dr',\n",
       " 'draw',\n",
       " 'dreams',\n",
       " 'dresser',\n",
       " 'drink',\n",
       " 'drinkin',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drizzling',\n",
       " 'dropped',\n",
       " 'drug',\n",
       " 'drunken',\n",
       " 'drvgsto',\n",
       " 'dryer',\n",
       " 'dubsack',\n",
       " 'duchess',\n",
       " 'dude',\n",
       " 'due',\n",
       " 'dun',\n",
       " 'dunno',\n",
       " 'durban',\n",
       " 'during',\n",
       " 'dwn',\n",
       " 'dx',\n",
       " 'e',\n",
       " 'each',\n",
       " 'earlier',\n",
       " 'earliest',\n",
       " 'early',\n",
       " 'earn',\n",
       " 'ears',\n",
       " 'earth',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eaten',\n",
       " 'eatin',\n",
       " 'ec',\n",
       " 'echo',\n",
       " 'edition',\n",
       " 'educational',\n",
       " 'edukkukayee',\n",
       " 'edwards',\n",
       " 'ee',\n",
       " 'eerulli',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'election',\n",
       " 'eleven',\n",
       " 'elliot',\n",
       " 'elsewhere',\n",
       " 'em',\n",
       " 'email',\n",
       " 'emailed',\n",
       " 'employer',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'ends',\n",
       " 'energy',\n",
       " 'engalnd',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entered',\n",
       " 'entitled',\n",
       " 'entry',\n",
       " 'enufcredeit',\n",
       " 'environment',\n",
       " 'epsilon',\n",
       " 'ertini',\n",
       " 'escalator',\n",
       " 'ese',\n",
       " 'espe',\n",
       " 'essential',\n",
       " 'etc',\n",
       " 'evaporated',\n",
       " 'eve',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'evenings',\n",
       " 'events',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everytime',\n",
       " 'ex',\n",
       " 'exact',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'excuse',\n",
       " 'excuses',\n",
       " 'exe',\n",
       " 'exhausted',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'expires',\n",
       " 'explicit',\n",
       " 'exposes',\n",
       " 'express',\n",
       " 'extra',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'fab',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'fact',\n",
       " 'faggy',\n",
       " 'fair',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'fallen',\n",
       " 'falls',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'fancy',\n",
       " 'fantasies',\n",
       " 'far',\n",
       " 'fassyole',\n",
       " 'fast',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'fault',\n",
       " 'fave',\n",
       " 'favor',\n",
       " 'favorite',\n",
       " 'fb',\n",
       " 'fear',\n",
       " 'feb',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'felt',\n",
       " 'feng',\n",
       " 'festival',\n",
       " 'fetch',\n",
       " 'few',\n",
       " 'fighting',\n",
       " 'fightng',\n",
       " 'fill',\n",
       " 'fills',\n",
       " 'filthyguys',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'fingers',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'fink',\n",
       " 'fire',\n",
       " 'first',\n",
       " 'fishhead',\n",
       " 'five',\n",
       " 'fix',\n",
       " 'fixed',\n",
       " 'fl',\n",
       " 'flaky',\n",
       " 'flame',\n",
       " 'flat',\n",
       " 'flavour',\n",
       " 'flights',\n",
       " 'flim',\n",
       " 'flute',\n",
       " 'fly',\n",
       " 'fml',\n",
       " 'fne',\n",
       " 'fo',\n",
       " 'foley',\n",
       " 'follow',\n",
       " 'followin',\n",
       " 'following',\n",
       " 'fone',\n",
       " 'food',\n",
       " 'fools',\n",
       " 'footie',\n",
       " 'footprints',\n",
       " 'footy',\n",
       " 'for',\n",
       " 'foregate',\n",
       " 'forfeit',\n",
       " 'forget',\n",
       " 'forgets',\n",
       " 'forgot',\n",
       " 'forum',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'four',\n",
       " 'fowler',\n",
       " 'fox',\n",
       " 'fr',\n",
       " 'fraction',\n",
       " 'frauds',\n",
       " 'free',\n",
       " 'freedom',\n",
       " 'freeentry',\n",
       " 'freemsg',\n",
       " 'freephone',\n",
       " 'freezing',\n",
       " 'freshers',\n",
       " 'fri',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'friendship',\n",
       " 'fring',\n",
       " 'frm',\n",
       " 'frnd',\n",
       " 'frnds',\n",
       " 'frndsship',\n",
       " 'from',\n",
       " 'front',\n",
       " 'fuck',\n",
       " 'fucking',\n",
       " 'full',\n",
       " 'fullonsms',\n",
       " 'fun',\n",
       " 'functions',\n",
       " 'fundamentals',\n",
       " 'further',\n",
       " 'fusion',\n",
       " 'future',\n",
       " 'fwd',\n",
       " 'fyi',\n",
       " 'g',\n",
       " 'gail',\n",
       " 'game',\n",
       " 'games',\n",
       " 'ganesh',\n",
       " 'gap',\n",
       " 'gaps',\n",
       " 'garments',\n",
       " 'gas',\n",
       " 'gb',\n",
       " 'gbp',\n",
       " 'gd',\n",
       " 'ge',\n",
       " 'generally',\n",
       " 'gent',\n",
       " 'genuine',\n",
       " 'germany',\n",
       " 'get',\n",
       " 'getiing',\n",
       " 'gets',\n",
       " 'getstop',\n",
       " 'gettin',\n",
       " 'getting',\n",
       " 'getzed',\n",
       " 'geva',\n",
       " 'gf',\n",
       " 'gift',\n",
       " 'gimme',\n",
       " 'girl',\n",
       " 'girls',\n",
       " 'give',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'glad',\n",
       " 'gn',\n",
       " 'go',\n",
       " 'god',\n",
       " 'gods',\n",
       " 'goes',\n",
       " 'goin',\n",
       " 'going',\n",
       " 'gold',\n",
       " 'gon',\n",
       " 'gona',\n",
       " 'gone',\n",
       " 'gong',\n",
       " 'gonna',\n",
       " 'good',\n",
       " 'goodmorning',\n",
       " 'goodnight',\n",
       " 'goodnite',\n",
       " 'goodnoon',\n",
       " 'google',\n",
       " 'gorgeous',\n",
       " 'gossip',\n",
       " 'got',\n",
       " 'goten',\n",
       " 'goto',\n",
       " 'govt',\n",
       " 'gpu',\n",
       " 'gr',\n",
       " 'gram',\n",
       " 'grasp',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greeting',\n",
       " 'grins',\n",
       " 'grl',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'grumble',\n",
       " 'gsex',\n",
       " 'gt',\n",
       " 'guaranteed',\n",
       " 'gucci',\n",
       " 'gud',\n",
       " 'guess',\n",
       " 'guide',\n",
       " 'guides',\n",
       " 'guilty',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gym',\n",
       " 'h',\n",
       " 'ha',\n",
       " 'habit',\n",
       " 'hack',\n",
       " 'had',\n",
       " 'haf',\n",
       " 'haha',\n",
       " 'hai',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'handset',\n",
       " 'hanuman',\n",
       " 'hanumanji',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'harish',\n",
       " 'harry',\n",
       " 'has',\n",
       " 'hav',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'havent',\n",
       " 'having',\n",
       " 'hcl',\n",
       " 'hdd',\n",
       " 'he',\n",
       " 'head',\n",
       " 'heads',\n",
       " 'headset',\n",
       " 'hear',\n",
       " 'heart',\n",
       " 'hearts',\n",
       " 'hee',\n",
       " 'hello',\n",
       " 'hellogorgeous',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hes',\n",
       " 'hey',\n",
       " 'hhahhaahahah',\n",
       " 'hi',\n",
       " 'hidden',\n",
       " 'high',\n",
       " 'hill',\n",
       " 'him',\n",
       " 'hip',\n",
       " 'his',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hitler',\n",
       " 'hl',\n",
       " 'hmm',\n",
       " ...]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(df.word_list)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# create the vectorizer object\n",
    "vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "\n",
    "# fit and transform on the original docs\n",
    "features = vectorizer.fit_transform(orig_docs)    \n",
    "\n",
    "# convert to a dense matrix\n",
    "features = features.todense()\n",
    "\n",
    "# look at the vector for each of the first 10 documents\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['SMS'], df['label'], test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiegiust/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[490   0]\n",
      " [ 10  58]]\n"
     ]
    }
   ],
   "source": [
    "# training the classifier \n",
    "svm = svm.SVC(C=1000)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# testing against testing set \n",
    "X_test = vectorizer.transform(X_test)\n",
    "y_pred = svm.predict(X_test) \n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test against new messages \n",
    "def pred(msg):\n",
    "    msg = vectorizer.transform([msg])\n",
    "    prediction = svm.predict(msg)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred('Whats up??')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

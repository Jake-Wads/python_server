{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction: Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples for the lesson\n",
    "sentence1 = \"Word Embeddings convert a Word into a number\"\n",
    "sentence2 = \"Computers do not like seeing a Word instead of a number\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Word Embeddings convert a Word into a number\n",
      "Sentence 2: Computers do not like seeing a Word instead of a number\n",
      "Dictionary:  ['Word', 'Embeddings', 'convert', 'a', 'into', 'number', 'Computers', 'do', 'not', 'like', 'seeing', 'instead', 'of']\n"
     ]
    }
   ],
   "source": [
    "dictionary = ['Word', 'Embeddings', 'convert', 'a', 'into', 'number', \n",
    "              'Computers', 'do', 'not', 'like', 'seeing', 'instead', 'of']\n",
    "print('Sentence 1: ' + sentence1)\n",
    "print('Sentence 2: ' + sentence2)\n",
    "print('Dictionary: ', dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectors\n",
    "a vector in this case is a one-hot encoded vector where 1 stands for the position where the word exists and 0 everywhere else.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 Word Embedding Vector:  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Sentence 2 Word Embedding Vector:  [1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "S1_vector = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "S2_vector = [1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "print('Sentence 1 Word Embedding Vector: ', S1_vector)\n",
    "print('Sentence 2 Word Embedding Vector: ', S2_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>convert</th>\n",
       "      <th>a</th>\n",
       "      <th>into</th>\n",
       "      <th>number</th>\n",
       "      <th>Computers</th>\n",
       "      <th>do</th>\n",
       "      <th>not</th>\n",
       "      <th>like</th>\n",
       "      <th>seeing</th>\n",
       "      <th>instead</th>\n",
       "      <th>of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Embeddings  convert  a  into  number  Computers  do  not  \\\n",
       "Sentence1     1           1        1  1     1       1          0   0    0   \n",
       "Sentence2     1           1        1  1     1       1          0   0    0   \n",
       "\n",
       "           like  seeing  instead  of  \n",
       "Sentence1     0       0        0   0  \n",
       "Sentence2     0       0        0   0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Sentence1' : S1_vector,\n",
    "              'Sentence2' : S1_vector\n",
    "             }, columns = ['Sentence1', 'Sentence2']).transpose()\n",
    "df.columns = dictionary\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:**  take in a corpus of documents and return a dataframe where each row is a document and each column is the complete dictionary (after normalizing the text) of all distinct words in the entire corpus.  The values in this matrix (stored as a dataframe) are equal to the count of that word appearing in that document.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Word Embeddings convert a Word into a number\n",
      "Sentence 2: Computers do not like seeing a Word instead of a number\n",
      "Dictionary:  ['Word', 'Embeddings', 'convert', 'a', 'into', 'number', 'Computers', 'do', 'not', 'like', 'seeing', 'instead', 'of']\n"
     ]
    }
   ],
   "source": [
    "print('Sentence 1: ' + sentence1)\n",
    "print('Sentence 2: ' + sentence2)\n",
    "print('Dictionary: ', dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vector for each document (sentence) and the number of instances of each word in the dictionary for that document. \n",
    "- We will combine these vectors to create a count matrix.   \n",
    "- We may either take the frequency (number of times a word has appeared in the document) or the presence(has the word appeared in the document?) to be the entry in the count matrix. But generally, frequency method is preferred over the latter.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Embeddings</th>\n",
       "      <th>convert</th>\n",
       "      <th>a</th>\n",
       "      <th>into</th>\n",
       "      <th>number</th>\n",
       "      <th>Computers</th>\n",
       "      <th>do</th>\n",
       "      <th>not</th>\n",
       "      <th>like</th>\n",
       "      <th>seeing</th>\n",
       "      <th>instead</th>\n",
       "      <th>of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Embeddings  convert  a  into  number  Computers  do  not  \\\n",
       "Sentence1     2           1        1  2     1       1          0   0    0   \n",
       "Sentence2     2           1        1  2     1       1          0   0    0   \n",
       "\n",
       "           like  seeing  instead  of  \n",
       "Sentence1     0       0        0   0  \n",
       "Sentence2     0       0        0   0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1_bow = [2, 1, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "S2_bow = [1, 0, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "df = pd.DataFrame({'Sentence1' : S1_bow,\n",
    "              'Sentence2' : S1_bow\n",
    "             }, columns = ['Sentence1', 'Sentence2']).transpose()\n",
    "df.columns = dictionary\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. wrangle data (acquire and parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the address of the web page to a variable named url.\n",
    "url = 'https://inshorts.com/en/read/business'\n",
    "\n",
    "# Request the server the content of the web page by using get(), and store the server’s response in the variable response.\n",
    "response = get(url)\n",
    "\n",
    "# Use BeautifulSoup to parse the html into a variable ('soup')\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Identify the key tags you need to extract the data you are looking for\n",
    "news_category = 'Business'\n",
    "news_data = []\n",
    "# using list comprehension to create a list of the data desired\n",
    "news_articles = [{'news_headline': headline.find('span', attrs={\"itemprop\": \"headline\"}).string,\n",
    "                  'news_article': article.find('div', attrs={\"itemprop\": \"articleBody\"}).string,\n",
    "                  'news_category': news_category}\n",
    "                 for headline, article in \n",
    "                 zip(soup.find_all('div', class_=[\"news-card-title news-right-box\"]),\n",
    "                     soup.find_all('div', class_=[\"news-card-content news-right-box\"]))\n",
    "                ]\n",
    "news_data.extend(news_articles)\n",
    "\n",
    "# Create a dataframe of the data desired\n",
    "news_df =  pd.DataFrame(news_data)\n",
    "\n",
    "# combine headline and article text and create a corpus of documents\n",
    "news_df['full_text'] = news_df[\"news_headline\"].map(str)+ '. ' + news_df[\"news_article\"]\n",
    "\n",
    "# Create a corpus of the column with the text you want to analyze.\n",
    "corp = news_df['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     I've been an idiot for not buying: Buffett's f...\n",
       "1     I'd be disgusted if someone celebrated $1tn m-...\n",
       "2     Billionaire Elon Musk personally owes $507 mil...\n",
       "3     Air India warns employees not to speak to medi...\n",
       "4     PepsiCo withdraws its lawsuit against 4 Gujara...\n",
       "5     I’m only 28, can take time to build my busines...\n",
       "6     Anil Ambani's wealth falls 60% in 2 months to ...\n",
       "7     Brexit is worse than Y2K for customers, says I...\n",
       "8     Delhi HC asks J&J to pay ₹25 lakh each to 4 hi...\n",
       "9     India secures additional oil supplies as Iran ...\n",
       "10    India again postpones retaliatory tariffs agai...\n",
       "11    Gujarat farmers seek compensation from PepsiCo...\n",
       "12    India's April jobless rate at 7.6%, highest si...\n",
       "13    JSW Group enters paints business, Parth Jindal...\n",
       "14    Qualcomm expects at least $4.5 billion from Ap...\n",
       "15    Ex-Alibaba exec Bhushan Patil quits as Paytm P...\n",
       "16    Standard Life to sell 1.78% stake in HDFC Life...\n",
       "17    Jet Airways down 20% on report bidders not kee...\n",
       "18    Foreign investors urge NSE to not challenge SE...\n",
       "19    Gates Foundation hires senior Tata exec as Ind...\n",
       "20    Bandhan Bank to cut promoter stake through off...\n",
       "21    Bandhan Bank reports 68% jump in March quarter...\n",
       "22    NCLAT allows banks to declare IL&FS accounts a...\n",
       "23    SBI links interest on large savings accounts t...\n",
       "24    India buffalo meat exports hit 6-yr low on wea...\n",
       "Name: full_text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leave out the last document to test the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# extract the bag of words\n",
    "# we will leave out the last document, so we can use that as a new document we will run the transform function on.  \n",
    "orig_docs = corp[:-1]\n",
    "print(orig_docs.shape)\n",
    "new_doc = corp[-1:]\n",
    "print(new_doc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### count vectorizer:  Convert a collection of text documents to a matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 3 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# create the vectorizer object\n",
    "vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1))\n",
    "\n",
    "# fit and transform on the original docs\n",
    "features = vectorizer.fit_transform(orig_docs)    \n",
    "\n",
    "# convert to a dense matrix\n",
    "features = features.todense()\n",
    "\n",
    "# look at the vector for each of the first 10 documents\n",
    "print(features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get feature names, or list of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '04', '10', '120', '13', '14', '16', '1tn', '20', '2016']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# look at the first 10 feature names (words in alphabetical order)\n",
    "print(feature_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create a dataframe out of the matrix and feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>04</th>\n",
       "      <th>10</th>\n",
       "      <th>120</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>1tn</th>\n",
       "      <th>20</th>\n",
       "      <th>2016</th>\n",
       "      <th>...</th>\n",
       "      <th>withheld</th>\n",
       "      <th>within</th>\n",
       "      <th>without</th>\n",
       "      <th>world</th>\n",
       "      <th>worse</th>\n",
       "      <th>would</th>\n",
       "      <th>writing</th>\n",
       "      <th>y2k</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 717 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  04  10  120  13  14  16  1tn  20  2016  ...    withheld  within  \\\n",
       "0    0   0   0    0   0   0   0    0   0     0  ...           0       0   \n",
       "1    0   0   0    0   0   0   0    1   0     0  ...           0       0   \n",
       "2    0   0   0    0   1   0   0    0   0     0  ...           0       0   \n",
       "3    0   0   0    0   0   0   0    0   0     0  ...           0       0   \n",
       "4    0   0   0    0   0   0   0    0   0     0  ...           0       0   \n",
       "\n",
       "   without  world  worse  would  writing  y2k  year  years  \n",
       "0        0      1      0      1        0    0     1      0  \n",
       "1        0      0      0      1        0    0     0      0  \n",
       "2        0      0      0      0        0    0     0      0  \n",
       "3        1      0      0      0        1    0     0      0  \n",
       "4        0      0      0      0        0    0     0      0  \n",
       "\n",
       "[5 rows x 717 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=features,\n",
    "                  columns=feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataframe we can work with to model:  sentiment analysis, topic modeling, etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

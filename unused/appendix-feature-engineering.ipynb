{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "\"Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.\"\n",
    "Jason Brownlee, [Machine Learning Mastery](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n",
    "\n",
    "1. Construct new features: Use domain knowledge, creating products of features, etc. \n",
    "1. Use recursive feature elimination to recursively remove attributes to meet the number of required features and then builds a model on those attributes that remain to see if you can you match or improve performance with a smaller subset.   \n",
    "1. Use backward elimination to recursively remove the worst performing features one by one till the overall performance of the model comes in acceptable range.\n",
    "1. Forward selection begins with an empty equation. Predictors are added one at a time beginning with the predictor with the highest correlation with the dependent variable. Variables of greater theoretical importance are entered first. Once in the equation, the variable remains there.\n",
    "1. Compare several of these feature selection methods. Select the best approach with model selection.\n",
    "1. To improve performance and/or understanding, subsample your data and redo your analysis for several samples.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:15.261747Z",
     "iopub.status.busy": "2022-02-03T20:13:15.260561Z",
     "iopub.status.idle": "2022-02-03T20:13:17.709643Z",
     "shell.execute_reply": "2022-02-03T20:13:17.710328Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import env\n",
    "import wrangle\n",
    "import split_scale\n",
    "\n",
    "# acquire data and remove null values \n",
    "df = wrangle.wrangle_grades()\n",
    "\n",
    "# split into train and test\n",
    "train, test = split_scale.split_my_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the feature engineering methods, we want to use the scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:17.729048Z",
     "iopub.status.busy": "2022-02-03T20:13:17.718610Z",
     "iopub.status.idle": "2022-02-03T20:13:17.731765Z",
     "shell.execute_reply": "2022-02-03T20:13:17.732519Z"
    }
   },
   "outputs": [],
   "source": [
    "# scale data using standard scaler\n",
    "scaler, train, test = split_scale.standard_scaler(train, test)\n",
    "\n",
    "# to return to original values\n",
    "# scaler, train, test = scaling.my_inv_transform(scaler, train, test)\n",
    "\n",
    "X_train = train.drop(columns='final_grade')\n",
    "y_train = train[['final_grade']]\n",
    "X_test = test.drop(columns='final_grade')\n",
    "y_test = test[['final_grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Methods\n",
    "\n",
    "- Goals:  You want to keep the attributes with highest correlation to the target variable and of those features, if two are highly correlated with each other, remove one of them. \n",
    "- Filter and take only the subset of the relevant features. \n",
    "- The model is built after selecting the features. \n",
    "\n",
    "### Correlation Thresholds\n",
    "\n",
    "- The filtering can be done using correlation matrix with Pearson correlation.\n",
    "- For example, if you had a real-estate dataset with 'Floor Area (Sq. Ft.)' and 'Floor Area (Sq. Meters)' as separate features, you can safely remove one of them.  Which one should you remove? Well, you'd first calculate all pair-wise correlations. Then, if the correlation between a pair of features is above a given threshold, you'd remove the one that has larger mean absolute correlation with other features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:17.750735Z",
     "iopub.status.busy": "2022-02-03T20:13:17.749754Z",
     "iopub.status.idle": "2022-02-03T20:13:18.086890Z",
     "shell.execute_reply": "2022-02-03T20:13:18.087770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(6,5))\n",
    "cor = train.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view just the correlations of each attribute with the target variable, and filter down to only those above a certain value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.097392Z",
     "iopub.status.busy": "2022-02-03T20:13:18.096457Z",
     "iopub.status.idle": "2022-02-03T20:13:18.101100Z",
     "shell.execute_reply": "2022-02-03T20:13:18.101959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exam1          0.984101\n",
       "exam2          0.922598\n",
       "exam3          0.950309\n",
       "final_grade    1.000000\n",
       "Name: final_grade, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"final_grade\"])\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.5]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the correlation of each of these variables, exam 1 is most correlated with final grade and all three exams are correlated with each other.  So using this method, we may decide to only use one exam or we may want to create new features, such as `exam2_delta = exam2 - exam1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select K Best\n",
    "\n",
    "- `SelectKBest` removes all but the highest scoring features\n",
    "- Scores are the test statistic for the chosen function or test (Chi-squared, F-regression, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.107231Z",
     "iopub.status.busy": "2022-02-03T20:13:18.105482Z",
     "iopub.status.idle": "2022-02-03T20:13:18.162907Z",
     "shell.execute_reply": "2022-02-03T20:13:18.163793Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using f-regression\n",
    "\n",
    "Linear model for testing the individual effect of each of many regressors. This is a scoring function to be used in a feature selection procedure, not a free standing feature selection procedure.\n",
    "\n",
    "This is done in 2 steps:\n",
    "\n",
    "1. The correlation between each regressor and the target is computed.  \n",
    "2. It is converted to an F score then to a p-value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.171049Z",
     "iopub.status.busy": "2022-02-03T20:13:18.170108Z",
     "iopub.status.idle": "2022-02-03T20:13:18.179600Z",
     "shell.execute_reply": "2022-02-03T20:13:18.180387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 selected features\n",
      "['exam1', 'exam3']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "f_selector = SelectKBest(f_regression, k=2)\n",
    "\n",
    "f_selector.fit(X_train, y_train)\n",
    "\n",
    "f_support = f_selector.get_support()\n",
    "f_feature = X_train.loc[:,f_support].columns.tolist()\n",
    "\n",
    "print(str(len(f_feature)), 'selected features')\n",
    "print(f_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Methods\n",
    "\n",
    "- A wrapper method needs one machine learning algorithm and uses its performance as evaluation criteria. \n",
    "- You feed the features to the selected Machine Learning algorithm and based on the model performance you add/remove the features. \n",
    "- This is an iterative and computationally expensive process but it is more accurate than the filter method.\n",
    "- Methods include: Backward Elimination, Forward Selection, Bidirectional Elimination and RFE. \n",
    "\n",
    "### Backward Elimination using OLS\n",
    "\n",
    "- We check the performance of the model and then iteratively remove the worst performing features one by one till the overall performance of the model comes in acceptable range.\n",
    "- The performance metric used here to evaluate feature performance is pvalue. If the pvalue is above 0.05 then we remove the feature, else we keep it.\n",
    "- We will first run one iteration here just to get an idea of the concept and then we will run the same code in a loop, which will give the final set of features. \n",
    "- Ordinary Least Squares (OLS) can be used to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.185680Z",
     "iopub.status.busy": "2022-02-03T20:13:18.184061Z",
     "iopub.status.idle": "2022-02-03T20:13:18.554157Z",
     "shell.execute_reply": "2022-02-03T20:13:18.555163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>final_grade</td>   <th>  R-squared (uncentered):</th>      <td>   0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   711.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 03 Feb 2022</td> <th>  Prob (F-statistic):</th>          <td>5.97e-60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:13:18</td>     <th>  Log-Likelihood:    </th>          <td>  32.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    81</td>      <th>  AIC:               </th>          <td>  -56.72</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    77</td>      <th>  BIC:               </th>          <td>  -47.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>student_id</th> <td>    0.0041</td> <td>    0.019</td> <td>    0.217</td> <td> 0.829</td> <td>   -0.034</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exam1</th>      <td>    0.8038</td> <td>    0.060</td> <td>   13.288</td> <td> 0.000</td> <td>    0.683</td> <td>    0.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exam2</th>      <td>   -0.0366</td> <td>    0.057</td> <td>   -0.642</td> <td> 0.523</td> <td>   -0.150</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exam3</th>      <td>    0.2285</td> <td>    0.063</td> <td>    3.624</td> <td> 0.001</td> <td>    0.103</td> <td>    0.354</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.132</td> <th>  Durbin-Watson:     </th> <td>   1.848</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.209</td> <th>  Jarque-Bera (JB):  </th> <td>   2.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.291</td> <th>  Prob(JB):          </th> <td>   0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.374</td> <th>  Cond. No.          </th> <td>    7.19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:            final_grade   R-squared (uncentered):                   0.974\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.972\n",
       "Method:                 Least Squares   F-statistic:                              711.7\n",
       "Date:                Thu, 03 Feb 2022   Prob (F-statistic):                    5.97e-60\n",
       "Time:                        14:13:18   Log-Likelihood:                          32.358\n",
       "No. Observations:                  81   AIC:                                     -56.72\n",
       "Df Residuals:                      77   BIC:                                     -47.14\n",
       "Df Model:                           4                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "student_id     0.0041      0.019      0.217      0.829      -0.034       0.042\n",
       "exam1          0.8038      0.060     13.288      0.000       0.683       0.924\n",
       "exam2         -0.0366      0.057     -0.642      0.523      -0.150       0.077\n",
       "exam3          0.2285      0.063      3.624      0.001       0.103       0.354\n",
       "==============================================================================\n",
       "Omnibus:                        3.132   Durbin-Watson:                   1.848\n",
       "Prob(Omnibus):                  0.209   Jarque-Bera (JB):                2.463\n",
       "Skew:                           0.291   Prob(JB):                        0.292\n",
       "Kurtosis:                       2.374   Cond. No.                         7.19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# create the OLS object:\n",
    "ols_model = sm.OLS(y_train, X_train)\n",
    "\n",
    "# fit the model:\n",
    "fit = ols_model.fit()\n",
    "\n",
    "# summarize:\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the summary above, we see that the p-value for exam 2 is very high, while exams 1 and 3 are minimal.\n",
    "\n",
    "Below, we will use OLS for backwards elimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.567395Z",
     "iopub.status.busy": "2022-02-03T20:13:18.566382Z",
     "iopub.status.idle": "2022-02-03T20:13:18.587697Z",
     "shell.execute_reply": "2022-02-03T20:13:18.588729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exam1', 'exam3']\n"
     ]
    }
   ],
   "source": [
    "cols = list(X_train.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X_train[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y_train,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)\n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this above, we will want to keep only exam1 and exam3, as we saw in the summary table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE) \n",
    "\n",
    "- Recursively removes attributes and then builds a model on those attributes that remain. \n",
    "- It uses accuracy metric to rank the feature according to their importance. \n",
    "- The RFE method takes the model to be used and the number of required features as input. \n",
    "- It returns the ranking of all the variables, 1 being most important, along with its support, True being relevant feature and False being irrelevant feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.593574Z",
     "iopub.status.busy": "2022-02-03T20:13:18.592550Z",
     "iopub.status.idle": "2022-02-03T20:13:18.621906Z",
     "shell.execute_reply": "2022-02-03T20:13:18.622671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False  True]\n",
      "[3 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "#Initializing RFE model, with parameter to select top 2 features. \n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "\n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X_train,y_train)  \n",
    "\n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y_train)\n",
    "\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we took LinearRegression model with 2 features and RFE gave feature ranking as above, but the selection of number ‘2’ was random. \n",
    "- Now we need to find the optimum number of features, for which the accuracy is the highest. \n",
    "- We do that by using loop starting with 1 feature and going up to 3. We then take the one for which the accuracy is highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.642387Z",
     "iopub.status.busy": "2022-02-03T20:13:18.641465Z",
     "iopub.status.idle": "2022-02-03T20:13:18.673310Z",
     "shell.execute_reply": "2022-02-03T20:13:18.674362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 2\n",
      "Score with 2 features: 0.965926\n"
     ]
    }
   ],
   "source": [
    "number_of_features_list=np.arange(1,3)\n",
    "high_score=0\n",
    "\n",
    "#Variable to store the optimum features\n",
    "number_of_features=0           \n",
    "score_list =[]\n",
    "\n",
    "for n in range(len(number_of_features_list)):\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model, n_features_to_select=number_of_features_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        number_of_features = number_of_features_list[n]\n",
    "\n",
    "print(\"Optimum number of features: %d\" %number_of_features)\n",
    "print(\"Score with %d features: %f\" % (number_of_features, high_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As seen from above code, the optimum number of features is 2. \n",
    "- We now feed 2 as number of features to RFE and get the final set of features given by RFE method, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.690560Z",
     "iopub.status.busy": "2022-02-03T20:13:18.689564Z",
     "iopub.status.idle": "2022-02-03T20:13:18.702355Z",
     "shell.execute_reply": "2022-02-03T20:13:18.703285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['exam1', 'exam3'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = list(X_train.columns)\n",
    "model = LinearRegression()\n",
    "\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "\n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X_train,y_train)  \n",
    "\n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y_train)\n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded Methods\n",
    "\n",
    "- Embedded methods are iterative in a sense that takes care of each iteration of the model training process and carefully extract those features which contribute the most to the training for a particular iteration.\n",
    "- Regularization methods are the most commonly used embedded methods which penalize a feature given a coefficient threshold.\n",
    "- E.g. Lasso regularization. If the feature is irrelevant, lasso penalizes it’s coefficient by making it 0. Hence the features with coefficient = 0 are removed and the rest are taken.\n",
    "- Other regularization algorithms: Elastic Net, Ridge Regression, and Regularized Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.713532Z",
     "iopub.status.busy": "2022-02-03T20:13:18.712682Z",
     "iopub.status.idle": "2022-02-03T20:13:18.782240Z",
     "shell.execute_reply": "2022-02-03T20:13:18.783038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha using built-in LassoCV: 0.013949\n",
      "Best score using built-in LassoCV: 0.973301\n",
      "Lasso picked 2 variables and eliminated the other 2 variables\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "reg = LassoCV()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X_train,y_train))\n",
    "coef = pd.Series(reg.coef_, index = X_train.columns)\n",
    "\n",
    "\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the value of $\\alpha$ the fewer the features have non-zero values, the more features that have zero-values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.788627Z",
     "iopub.status.busy": "2022-02-03T20:13:18.786211Z",
     "iopub.status.idle": "2022-02-03T20:13:18.949530Z",
     "shell.execute_reply": "2022-02-03T20:13:18.950301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature importance using Lasso Model')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp_coef = coef.sort_values()\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (4.0, 5.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Dimensionality Reduction\n",
    "\n",
    "### Principal component analysis (PCA) \n",
    "\n",
    "- Unsupervised algorithm\n",
    "- Creates linear combinations of the original features\n",
    "- The new features are orthogonal, therefore, uncorrelated. \n",
    "- They are ranked in order of their \"explained variance.\" \n",
    "- PC1 explains the most variance in your dataset, PC2 explains the second-most variance, etc.\n",
    "- You might decide to keep only as many principal components as needed to reach a cumulative explained variance of 90%.\n",
    "- Always normalize your dataset before performing PCA because the transformation is dependent on scale.\n",
    "- Versatile, fast, simple to implement\n",
    "- There exist several variations and extensions (i.e. kernel PCA, sparse PCA, etc.) to tackle specific roadblocks.\n",
    "- The new principal components or features are not interpretable\n",
    "- `sklearn.decomposition.PCA(n_components=None, copy=True, whiten=False, svd_solver=’auto’, tol=0.0, iterated_power=’auto’, random_state=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:13:18.960940Z",
     "iopub.status.busy": "2022-02-03T20:13:18.959756Z",
     "iopub.status.idle": "2022-02-03T20:13:18.969298Z",
     "shell.execute_reply": "2022-02-03T20:13:18.970139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "81\n",
      "[0.72956108]\n",
      "[[-1.4843675 ]\n",
      " [-1.14217214]\n",
      " [-0.04796074]\n",
      " [-0.9912816 ]\n",
      " [-2.32558288]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1, copy=True, whiten=False, svd_solver='auto', random_state=123)\n",
    "pca.fit(X_train)\n",
    "X = pca.transform(X_train)\n",
    "print(pca.n_components_)\n",
    "print(len(X))\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(X[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- the optimum number of features is 2\n",
    "- exam1 and exam3 were the top performing features\n",
    "- In your exercises, you will use RFE, recursive feature elimination, to write UDF's to identify ideal number of features, find what those are, and create new train and test dataframes with those two features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Our scenario continues:  \n",
    "As a customer analyst, I want to know who has spent the most money with us over their lifetime. I have monthly charges and tenure, so I think I will be able to use those two attributes as features to estimate total_charges. I need to do this within an average of $5.00 per customer. \n",
    "\n",
    "1. Write a function, `select_kbest_freg()` that takes X_train, y_train and k as input (X_train and y_train should not be scaled!) and returns a list of the top k features. \n",
    "2. Write a function, `select_kbest_freg()` that takes X_train, y_train (scaled) and k as input and returns a list of the top k features. \n",
    "3. Write a function, `ols_backware_elimination()` that takes X_train and y_train (scaled) as input and returns selected features based on the ols backwards elimination method. \n",
    "4. Write a function, `lasso_cv_coef()` that takes X_train and y_train as input and returns the coefficients for each feature, along with a plot of the features and their weights. \n",
    "5. Write 3 functions, the first computes the number of optimum features (n) using rfe, the second takes n as input and returns the top n features, and the third takes the list of the top n features as input and returns a new X_train and X_test dataframe with those top features , `recursive_feature_elimination()` that computes the optimum number of features (n) and returns the top n features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

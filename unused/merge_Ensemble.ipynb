{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "\n",
    "Ensemble methods are basically building a model full of many submodels.\n",
    "\n",
    "For example, when creating a decision tree, ideally we want to find the optimal subtree that can also be thought of as a decision tree that satisfies our model. To do that we could use the ensemble method known as Random Forest.\n",
    "\n",
    "## BAGGING  \n",
    "- Name comes from “bootstrap aggregation.” \n",
    "- A way to improve a model without changing anything except the training set\n",
    "- It works by aggregating multiple random versions of the training set\n",
    "\n",
    "Imagine that we randomly sample data in our data set. For instance, we take a subset that overlooks something like the poisonous Bolete mushroom. For each one of these subsamples we train a decision tree using our metrics like the GINI impurity or information gain (Figure 5-4). For each of these models we then have an accuracy, precision, and recall associated with each.\n",
    "\n",
    "We generate a set of decision trees that we can aggregate by finding the majority vote of a classification.    \n",
    "This drastically improves performance because it reduces variability in the prediction while not adding in bias. \n",
    "So, when one decision tree has a lot of noise contained within it, the decision trees in aggregate will average out. This is similar to the central limit theorem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Precision: \n",
    "- How on point is the classification?\n",
    "- Out of all the positive matches the model finds, how many of them were correct?\n",
    "- Precision = True Positives / (True Positives + False Positives)\n",
    "\n",
    "Recall:  \n",
    "- How sensitive is the model? \n",
    "- A measure of whether all the relevant instances were actually looked at.  \n",
    "- Recall = True Positives / (True Positives + False Negatives)\n",
    "\n",
    "Accuracy:  \n",
    "- The error rate of the model\n",
    "- How well does it do in aggregate?\n",
    "- Accuracy = (True Positives + True Negatives) / (Number of all responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
